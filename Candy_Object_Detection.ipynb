{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2d2782c2-f544-4dd8-b96a-eec7b5aa3a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "directory: /Users/larasabha/Desktop/Candy-object-detection\n",
      "structure created\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import json\n",
    "import yaml\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "\n",
    "project_root = Path.cwd()\n",
    "print(f\"directory: {project_root}\")\n",
    "\n",
    "dirs_to_create = [\n",
    "    project_root / \"Images\",\n",
    "    project_root / \"Annotation_CSV_Files\",\n",
    "    project_root / \"labels\",\n",
    "    project_root / \"dataset\" / \"images\" / \"train\",\n",
    "    project_root / \"dataset\" / \"images\" / \"val\",\n",
    "    project_root / \"dataset\" / \"labels\" / \"train\",\n",
    "    project_root / \"dataset\" / \"labels\" / \"val\",\n",
    "    project_root / \"test_results\"\n",
    "]\n",
    "\n",
    "for directory in dirs_to_create:\n",
    "    directory.mkdir(parents=True, exist_ok=True)\n",
    "print(\"structure created\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "add2eb25-9f21-4030-8ce1-8638c00f6bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "organizing dataset files\n",
      "no archive folder found\n",
      "moved 0 images to /Users/larasabha/Desktop/Candy-object-detection/Images\n",
      "moved 11 CSV files to /Users/larasabha/Desktop/Candy-object-detection/Annotation_CSV_Files\n",
      "final counts: 528 images, 11 CSV files\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def organize_dataset_files(root_dir=project_root):\n",
    "    \"\"\"\n",
    "    Images -> Images/\n",
    "    CSV annotation files -> Annotation_CSV_Files/\n",
    "    \"\"\"\n",
    "    print(\"organizing dataset files\")\n",
    "\n",
    "    archive_folders = [d for d in root_dir.iterdir() if d.is_dir() and 'candy' in d.name.lower()]\n",
    "    if archive_folders:\n",
    "        archive_folder = archive_folders[0]\n",
    "        print(f\"found archive folder: {archive_folder}\")\n",
    "        source_img_folder = archive_folder / \"Images\"\n",
    "        source_csv_folder = archive_folder / \"Annotation CSV Files\"\n",
    "    else:\n",
    "        print(\"no archive folder found\")\n",
    "        source_img_folder = root_dir / \"Images\"\n",
    "        source_csv_folder = root_dir / \"Annotation CSV Files\"\n",
    "\n",
    "    dest_img_folder = root_dir / \"Images\"\n",
    "    dest_csv_folder = root_dir / \"Annotation_CSV_Files\"\n",
    "    \n",
    "    moved_images = 0\n",
    "    moved_csvs = 0\n",
    "\n",
    "    if source_img_folder.exists():\n",
    "        for file in source_img_folder.iterdir():\n",
    "            if file.suffix.lower() in ['.jpg', '.jpeg', '.JPG', '.JPEG', '.png', '.PNG']:\n",
    "                dst = dest_img_folder / file.name\n",
    "                if not dst.exists():\n",
    "                    file.rename(dst)  # move file\n",
    "                    moved_images += 1\n",
    "        print(f\"moved {moved_images} images to {dest_img_folder}\")\n",
    "    else:\n",
    "        print(f\"images folder not found at {source_img_folder}\")\n",
    "\n",
    "    if source_csv_folder.exists():\n",
    "        for file in source_csv_folder.iterdir():\n",
    "            if file.suffix.lower() == '.csv':\n",
    "                dst = dest_csv_folder / file.name\n",
    "                if not dst.exists():\n",
    "                    file.rename(dst)\n",
    "                    moved_csvs += 1\n",
    "        print(f\"moved {moved_csvs} CSV files to {dest_csv_folder}\")\n",
    "    else:\n",
    "        print(f\"CSV folder not found at {source_csv_folder}\")\n",
    "\n",
    "    final_images = len(list(dest_img_folder.glob(\"*.[jJ][pP][gG]\"))) + \\\n",
    "                   len(list(dest_img_folder.glob(\"*.[jJ][pP][eE][gG]\"))) + \\\n",
    "                   len(list(dest_img_folder.glob(\"*.png\")))\n",
    "\n",
    "    final_csvs = len(list(dest_csv_folder.glob(\"*.csv\")))\n",
    "\n",
    "    print(f\"final counts: {final_images} images, {final_csvs} CSV files\")\n",
    "    return final_images > 0 and final_csvs > 0\n",
    "\n",
    "organize_dataset_files(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "64690e28-70b0-4887-9725-96741b86f693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting CSV annotations to YOLO format\n",
      "found 11 CSV files\n",
      "skipping empty file: Candy_Project_1930-1981_csv.csv\n",
      "skipping empty file: Candy_Project_2039-2092_csv.csv\n",
      "skipping empty file: Candy_Project_2359-2415_csv.csv\n",
      "skipping empty file: Candy_Project_1982-2038_csv.csv\n",
      "skipping empty file: Candy_Project_2147-2197_csv.csv\n",
      "skipping empty file: Candy_Project_2468-2496_csv.csv\n",
      "skipping empty file: Candy_Project_2093-2146_csv.csv\n",
      "skipping empty file: Candy_Project_2304-2358_csv.csv\n",
      "skipping empty file: Candy_Project_2253-2303_csv.csv\n",
      "skipping empty file: Candy_Project_2416-2467_csv.csv\n",
      "skipping empty file: Candy_Project_2198-2252_csv.csv\n",
      "no valid CSV files loaded\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_csv_to_yolo(csv_folder=project_root / \"Annotation_CSV_Files\", \n",
    "                       image_folder=project_root / \"Images\", \n",
    "                       output_labels=project_root / \"labels\"):\n",
    "    \n",
    "    print(\"converting CSV annotations to YOLO format\")\n",
    "    import random\n",
    "\n",
    "    # make sure output directory exists\n",
    "    output_labels.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    if not csv_folder.exists():\n",
    "        print(f\"CSV folder not found: {csv_folder}\")\n",
    "        return False\n",
    "    \n",
    "    csv_files = list(csv_folder.glob(\"*.csv\"))\n",
    "    if not csv_files:\n",
    "        print(\"no CSV files found\")\n",
    "        return False\n",
    "    \n",
    "    print(f\"found {len(csv_files)} CSV files\")\n",
    "    \n",
    "    df_list = []\n",
    "    for csv_file in csv_files:\n",
    "        try:\n",
    "            df = pd.read_csv(csv_file)\n",
    "            # check if the dataframe is empty or has no columns\n",
    "            if df.empty or df.columns.size == 0:\n",
    "                print(f\"skipping empty file: {csv_file.name}\")\n",
    "                continue\n",
    "            df_list.append(df)\n",
    "            print(f\"loaded {csv_file.name}\")\n",
    "        except pd.errors.EmptyDataError:\n",
    "            print(f\"skipping empty file: {csv_file.name}\")\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            print(f\"error loading {csv_file.name}: {e}\")\n",
    "    \n",
    "    if not df_list:\n",
    "        print(\"no valid CSV files loaded\")\n",
    "        return False\n",
    "        \n",
    "    # combine all annotation dataframes into one    \n",
    "    df = pd.concat(df_list, ignore_index=True)\n",
    "    print(f\"total annotations: {len(df)}\")\n",
    "    \n",
    "    try:\n",
    "        # extract class names from JSON in region_attributes column\n",
    "        df['class'] = df['region_attributes'].apply(lambda x: json.loads(x)['candy_type'])\n",
    "        class_names = sorted(df['class'].unique())\n",
    "        if \"Unknown\" not in class_names:\n",
    "            class_names.append(\"Unknown\")\n",
    "            print(\"added 'Unknown' class manually\")\n",
    "\n",
    "        class_to_id = {name: i for i, name in enumerate(class_names)}\n",
    "        \n",
    "        print(f\"found {len(class_names)} classes: {class_names}\")\n",
    "        \n",
    "        with open(project_root / \"classes.txt\", \"w\") as f:\n",
    "            for name in class_names:\n",
    "                f.write(name + \"\\n\")\n",
    "        \n",
    "        print(\"created classes.txt\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"error extracting classes: {e}\")\n",
    "        return False\n",
    "\n",
    "    all_images = [f for f in image_folder.glob(\"*\") if f.suffix.lower() in [\".jpg\", \".jpeg\", \".png\", \".JPG\", \".JPEG\", \".PNG\"]]\n",
    "    random.shuffle(all_images)\n",
    "    unknown_images = set(f.name for f in all_images[:5])\n",
    "    \n",
    "    converted_count = 0\n",
    "    for filename in df['filename'].unique():\n",
    "        img_path = image_folder / filename\n",
    "        label_path = output_labels / (img_path.stem + \".txt\")\n",
    "        \n",
    "        if not img_path.exists():\n",
    "            print(f\"image not found: {img_path}\")\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            img = Image.open(img_path)\n",
    "            img_w, img_h = img.size  # get image width and height\n",
    "        except Exception as e:\n",
    "            print(f\"failed to open image {filename}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # save class names to classes.txt for YOLO training\n",
    "        with open(label_path, \"w\") as f:\n",
    "            rows = df[df['filename'] == filename]\n",
    "            for _, row in rows.iterrows():\n",
    "                try:\n",
    "                    # parse bounding box and label info from JSON\n",
    "                    shape = json.loads(row['region_shape_attributes'])\n",
    "                    label = json.loads(row['region_attributes'])['candy_type']\n",
    "                    class_id = class_to_id[label]\n",
    "\n",
    "                    # get bounding box coordinates and size\n",
    "                    x, y, w, h = shape['x'], shape['y'], shape['width'], shape['height']\n",
    "                    # convert to YOLO format (normalized center x, center y, width, height)\n",
    "                    # YOLO format requires relative coordinates [0,1] normalized by image size\n",
    "                    x_center = (x + w / 2) / img_w\n",
    "                    y_center = (y + h / 2) / img_h\n",
    "                    w_norm = w / img_w\n",
    "                    h_norm = h / img_h\n",
    "                    \n",
    "                    f.write(f\"{class_id} {x_center:.6f} {y_center:.6f} {w_norm:.6f} {h_norm:.6f}\\n\")\n",
    "                except Exception as e:\n",
    "                    print(f\"skipping annotation in {filename}: {e}\")\n",
    "                    continue\n",
    "        \n",
    "        converted_count += 1\n",
    "\n",
    "        if filename in unknown_images:\n",
    "            unknown_id = class_to_id[\"Unknown\"]\n",
    "            # add a fixed dummy box (centered 20% box)\n",
    "            x_center, y_center, w_norm, h_norm = 0.5, 0.5, 0.2, 0.2\n",
    "            with open(label_path, \"a\") as f:\n",
    "                f.write(f\"{unknown_id} {x_center:.6f} {y_center:.6f} {w_norm:.6f} {h_norm:.6f}\\n\")\n",
    "            print(f\"'Unknown' label added into {filename}\")\n",
    "    \n",
    "    print(f\"converted {converted_count} image-label pairs\")\n",
    "    return True\n",
    "\n",
    "# run\n",
    "convert_csv_to_yolo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "29d46b27-bb19-4831-bde4-72f464e42475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating train/validation split\n",
      "found 528 images and 528 labels\n",
      "found 528 matching image-label pairs\n",
      "split: 475 training, 53 validation\n",
      "successfully created 475 training and 53 validation pairs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_train_val_split(train_ratio=0.9, root_dir=project_root):\n",
    "    \"\"\"train/validation split for YOLO training\"\"\"\n",
    "    \n",
    "    print(\"creating train/validation split\")\n",
    "    \n",
    "    # paths\n",
    "    images_dir = root_dir / \"Images\"\n",
    "    labels_dir = root_dir / \"labels\"\n",
    "    train_img_dir = root_dir / \"dataset/images/train\"\n",
    "    val_img_dir = root_dir / \"dataset/images/val\"\n",
    "    train_label_dir = root_dir / \"dataset/labels/train\"\n",
    "    val_label_dir = root_dir / \"dataset/labels/val\"\n",
    "    \n",
    "    # check if source directories exist\n",
    "    if not images_dir.exists() or not labels_dir.exists():\n",
    "        print(\"images or labels directory not found\")\n",
    "        return False\n",
    "\n",
    "    # collect image files\n",
    "    image_files = [f.name for f in images_dir.glob(\"*\") if f.suffix.lower() in [\".jpg\", \".jpeg\", \".JPG\", \".JPEG\", \".png\", \".PNG\"]]\n",
    "\n",
    "    # collect label files\n",
    "    label_files = [f.name for f in labels_dir.glob(\"*.txt\")]\n",
    "\n",
    "    print(f\"found {len(image_files)} images and {len(label_files)} labels\")\n",
    "\n",
    "    # match image label pairs by filename\n",
    "    matched_pairs = []\n",
    "    for img_file in image_files:\n",
    "        base_name = Path(img_file).stem\n",
    "        label_file = base_name + \".txt\"\n",
    "        if label_file in label_files:\n",
    "            matched_pairs.append((img_file, label_file))\n",
    "\n",
    "    print(f\"found {len(matched_pairs)} matching image-label pairs\")\n",
    "\n",
    "    if len(matched_pairs) == 0:\n",
    "        print(\"no matching pairs found\")\n",
    "        return False\n",
    "\n",
    "    # shuffle and split\n",
    "    random.seed(42)\n",
    "    random.shuffle(matched_pairs)\n",
    "\n",
    "    split_idx = int(len(matched_pairs) * train_ratio)\n",
    "    train_pairs = matched_pairs[:split_idx]\n",
    "    val_pairs = matched_pairs[split_idx:]\n",
    "\n",
    "    print(f\"split: {len(train_pairs)} training, {len(val_pairs)} validation\")\n",
    "\n",
    "    # copy training files\n",
    "    train_success = 0\n",
    "    val_success = 0\n",
    "\n",
    "    for img_file, label_file in train_pairs:\n",
    "        try:\n",
    "            shutil.copy2(images_dir / img_file, train_img_dir / img_file)\n",
    "            shutil.copy2(labels_dir / label_file, train_label_dir / label_file)\n",
    "            train_success += 1\n",
    "        except Exception as e:\n",
    "            print(f\"failed to copy training pair {img_file}: {e}\")\n",
    "\n",
    "    # copy validation files\n",
    "    for img_file, label_file in val_pairs:\n",
    "        try:\n",
    "            shutil.copy2(images_dir / img_file, val_img_dir / img_file)\n",
    "            shutil.copy2(labels_dir / label_file, val_label_dir / label_file)\n",
    "            val_success += 1\n",
    "        except Exception as e:\n",
    "            print(f\"failed to copy validation pair {img_file}: {e}\")\n",
    "\n",
    "    print(f\"successfully created {train_success} training and {val_success} validation pairs\")\n",
    "    return True\n",
    "\n",
    "# run the split\n",
    "create_train_val_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f61b64d7-77d6-4405-9e24-ffec8781bf26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating data.yaml\n",
      "created data.yaml with 9 classes\n",
      "classes: ['100_Grand', '3_Musketeers', 'Baby_Ruth', 'Butterfingers', 'Crunch', 'Midnight_Milky_Way', 'Milky_Way', 'Snickers', 'Twix']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_data_yaml(root_dir):\n",
    "    \"\"\"create data.yaml file\"\"\"\n",
    "    \n",
    "    print(\"creating data.yaml\")\n",
    "    \n",
    "    # path to the file that contains class names\n",
    "    classes_file = root_dir / \"classes.txt\"\n",
    "    \n",
    "    # try reading class names from classes.txt\n",
    "    try:\n",
    "        with open(classes_file, \"r\") as f:\n",
    "            class_names = [line.strip() for line in f.readlines() if line.strip()]\n",
    "    except FileNotFoundError:\n",
    "        print(f\"{classes_file} not found!\")\n",
    "        return False\n",
    "\n",
    "    # prepare dictionary with dataset info\n",
    "    data_content = {\n",
    "        'path': str(root_dir / 'dataset'),       # path for YOLO training\n",
    "        'train': 'images/train',\n",
    "        'val': 'images/val',\n",
    "        'nc': len(class_names),                  # # of classes\n",
    "        'names': class_names                     # list of class names\n",
    "    }\n",
    "\n",
    "    # write the YAML\n",
    "    output_yaml = root_dir / 'data.yaml'\n",
    "    with open(output_yaml, 'w') as f:\n",
    "        yaml.dump(data_content, f, default_flow_style=False, sort_keys=False)\n",
    "\n",
    "    print(f\"created data.yaml with {len(class_names)} classes\")\n",
    "    print(f\"classes: {class_names}\")\n",
    "    return True\n",
    "\n",
    "# run the function\n",
    "create_data_yaml(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e9a30d-7197-4cb6-9cc1-f207f111452c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(epochs=100, img_size=640, batch_size=16, root_dir=project_root):\n",
    "    \"\"\"train YOLOv8 model\"\"\"\n",
    "    \n",
    "    print(\"starting model training\")\n",
    "    \n",
    "    # path to data.yaml\n",
    "    data_yaml = root_dir / \"data.yaml\"\n",
    "    \n",
    "    # check if data.yaml exists\n",
    "    if not data_yaml.exists():\n",
    "        print(f\"{data_yaml} not found\")\n",
    "        return False\n",
    "\n",
    "    try:\n",
    "        # load base model\n",
    "        model = YOLO('yolov8n.pt')  # will auto download\n",
    "\n",
    "        # train the model with provided parameters\n",
    "        results = model.train(\n",
    "            data=str(data_yaml),        # path to data.yaml\n",
    "            epochs=epochs,              # # of training epochs\n",
    "            imgsz=img_size,             # image input size\n",
    "            batch=batch_size,           # batch size\n",
    "            name='candy_detection',     # training run name\n",
    "            patience=20,                # early stopping patience\n",
    "            save=True,                  # save final weights\n",
    "            plots=True                  # save training plots\n",
    "        )\n",
    "\n",
    "        print(\"training completed\")\n",
    "        print(f\"results saved in: runs/detect/candy_detection/\")\n",
    "\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"training failed: {e}\")\n",
    "        return False\n",
    "\n",
    "train_model(epochs=20)  # reduced epochs for faster training -> change to 100 for complete training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1df3ee6f-e90d-41fb-9424-35fac6b816a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found model: runs/detect/train2/weights/best.pt\n"
     ]
    }
   ],
   "source": [
    "# check for existing trained model\n",
    "def find_best_model():\n",
    "    \"\"\"find the best trained model\"\"\"\n",
    "    \n",
    "   # list of common paths\n",
    "    possible_paths = [\n",
    "        \"runs/detect/candy_detection/weights/best.pt\",\n",
    "        \"runs/detect/train/weights/best.pt\",\n",
    "        \"runs/detect/train2/weights/best.pt\",\n",
    "        \"best.pt\",\n",
    "        \"my_model.pt\"\n",
    "    ]\n",
    "    \n",
    "    # search for the first valid path\n",
    "    for path in possible_paths:\n",
    "        if os.path.exists(path):\n",
    "            print(f\"Found model: {path}\")\n",
    "            return path  # return the first match\n",
    "\n",
    "    print(\"no trained model found\")\n",
    "    return None\n",
    "\n",
    "# path for best model\n",
    "model_path = find_best_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9c7375d8-cc78-4bcc-9e33-2d45f1a289f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing detection on: /Users/larasabha/Desktop/image.jpg\n",
      "model loaded: runs/detect/train2/weights/best.pt\n",
      "image size: 194x259\n",
      "\n",
      "0: 640x480 2 Twixs, 50.1ms\n",
      "Speed: 1.5ms preprocess, 50.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "found 2 detections:\n",
      "  1. Twix (0.93)\n",
      "  2. Twix (0.87)\n",
      "result saved to: /Users/larasabha/Desktop/Candy-object-detection/test_results/detection_result.jpg\n"
     ]
    }
   ],
   "source": [
    "def test_single_image(image_path, model_path=None, conf_threshold=0.5):\n",
    "    \"\"\"test detection on a single image\"\"\"\n",
    "    \n",
    "    print(f\"testing detection on: {image_path}\")\n",
    "    \n",
    "    # find model if not provided\n",
    "    if model_path is None:\n",
    "        model_path = find_best_model()\n",
    "        if model_path is None:\n",
    "            return False\n",
    "    \n",
    "    # check image exists\n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"image not found: {image_path}\")\n",
    "        return False\n",
    "    \n",
    "    # load model\n",
    "    try:\n",
    "        model = YOLO(model_path)\n",
    "        print(f\"model loaded: {model_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"error loading model: {e}\")\n",
    "        return False\n",
    "    \n",
    "    # load image\n",
    "    try:\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            print(\"could not load image\")\n",
    "            return False\n",
    "        \n",
    "        height, width = image.shape[:2]\n",
    "        print(f\"image size: {width}x{height}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"error loading image: {e}\")\n",
    "        return False\n",
    "    \n",
    "    # run detection\n",
    "    try:\n",
    "        results = model(image, conf=conf_threshold)\n",
    "        \n",
    "        detections = []\n",
    "        result_image = image.copy()\n",
    "        \n",
    "        for result in results:\n",
    "            if hasattr(result, 'boxes') and result.boxes is not None:\n",
    "                for box in result.boxes:\n",
    "                    if box.xyxy is None or box.conf is None or box.cls is None:\n",
    "                        continue\n",
    "                    \n",
    "                    # get detection\n",
    "                    x1, y1, x2, y2 = map(int, box.xyxy[0].cpu().numpy())\n",
    "                    conf = float(box.conf[0].cpu().numpy())\n",
    "                    class_id = int(box.cls[0].cpu().numpy())\n",
    "                    class_name = model.names.get(class_id, f\"Class_{class_id}\")\n",
    "                    \n",
    "                    detections.append({\n",
    "                        'class': class_name,\n",
    "                        'confidence': conf,\n",
    "                        'box': [x1, y1, x2, y2]\n",
    "                    })\n",
    "                    \n",
    "                    # draw on image\n",
    "                    color = (0, 255, 0)  # Green\n",
    "                    cv2.rectangle(result_image, (x1, y1), (x2, y2), color, 2)\n",
    "                    cv2.putText(result_image, f\"{class_name} {conf:.2f}\", \n",
    "                              (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                              0.6, color, 2)\n",
    "        \n",
    "        print(f\"found {len(detections)} detections:\")\n",
    "        for i, det in enumerate(detections):\n",
    "            print(f\"  {i+1}. {det['class']} ({det['confidence']:.2f})\")\n",
    "\n",
    "        os.makedirs(\"test_results\", exist_ok=True)\n",
    "\n",
    "        # save result\n",
    "        output_path = Path(\"test_results\") / \"detection_result.jpg\"\n",
    "        cv2.imwrite(str(output_path), result_image)\n",
    "        print(f\"result saved to: {output_path.resolve()}\")\n",
    "        \n",
    "        return True, detections, result_image\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"error during detection: {e}\")\n",
    "        return False, [], None\n",
    "\n",
    "# test with desktop image (change path as needed)\n",
    "desktop_image = str(Path.home() / \"Desktop\" / \"image.jpg\")\n",
    "if os.path.exists(desktop_image):\n",
    "    test_single_image(desktop_image, model_path)\n",
    "else:\n",
    "    print(f\"no test image found at {desktop_image}\")\n",
    "    print(\"place an image named 'image.jpg' on your Desktop to test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7135d21e-80e9-4049-809d-6f874fdbceae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing detection on images in: Images\n",
      "model loaded: runs/detect/train2/weights/best.pt\n",
      "found 528 images\n",
      "\n",
      "0: 480x640 1 Butterfingers, 1 Midnight_Milky_Way, 1 Snickers, 1 Twix, 55.6ms\n",
      "Speed: 5.6ms preprocess, 55.6ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "IMG_2165.JPG: 4 detections\n",
      "\n",
      "0: 480x640 1 3_Musketeers, 1 Butterfingers, 1 Midnight_Milky_Way, 1 Snickers, 46.5ms\n",
      "Speed: 2.8ms preprocess, 46.5ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "IMG_2171.JPG: 4 detections\n",
      "\n",
      "0: 480x640 1 Butterfingers, 1 Milky_Way, 1 Snickers, 1 Twix, 50.2ms\n",
      "Speed: 2.7ms preprocess, 50.2ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "IMG_2159.JPG: 4 detections\n",
      "\n",
      "0: 480x640 1 Crunch, 1 Milky_Way, 1 Snickers, 1 Twix, 45.6ms\n",
      "Speed: 2.2ms preprocess, 45.6ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "IMG_2398.JPG: 4 detections\n",
      "\n",
      "0: 480x640 1 Crunch, 1 Midnight_Milky_Way, 1 Snickers, 1 Twix, 50.7ms\n",
      "Speed: 2.4ms preprocess, 50.7ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "IMG_2401.JPG: 4 detections\n",
      "\n",
      "0: 480x640 1 100_Grand, 1 Crunch, 1 Milky_Way, 1 Twix, 49.2ms\n",
      "Speed: 3.3ms preprocess, 49.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "IMG_2367.JPG: 4 detections\n",
      "\n",
      "0: 480x640 1 100_Grand, 1 Crunch, 1 Midnight_Milky_Way, 1 Twix, 43.9ms\n",
      "Speed: 2.2ms preprocess, 43.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "IMG_2373.JPG: 4 detections\n",
      "\n",
      "0: 480x640 1 Crunch, 1 Midnight_Milky_Way, 1 Milky_Way, 1 Snickers, 45.7ms\n",
      "Speed: 2.5ms preprocess, 45.7ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "IMG_2415.JPG: 4 detections\n",
      "\n",
      "0: 480x640 1 Crunch, 1 Midnight_Milky_Way, 1 Milky_Way, 1 Twix, 45.7ms\n",
      "Speed: 2.0ms preprocess, 45.7ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "IMG_2429.JPG: 4 detections\n",
      "\n",
      "0: 480x640 1 100_Grand, 1 Baby_Ruth, 1 Crunch, 1 Midnight_Milky_Way, 51.9ms\n",
      "Speed: 3.1ms preprocess, 51.9ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "IMG_2213.JPG: 4 detections\n",
      "summary: 40 total detections in 10 images\n"
     ]
    }
   ],
   "source": [
    "def test_multiple_images(image_folder=\"Images\", model_path=None, conf_threshold=0.5):\n",
    "    \"\"\"test detection on multiple images\"\"\"\n",
    "    \n",
    "    image_folder = Path(image_folder)\n",
    "    \n",
    "    print(f\"testing detection on images in: {image_folder}\")\n",
    "    \n",
    "    if model_path is None:\n",
    "        model_path = find_best_model()\n",
    "        if model_path is None:\n",
    "            return False\n",
    "    \n",
    "    # load model\n",
    "    try:\n",
    "        model = YOLO(model_path)\n",
    "        print(f\"model loaded: {model_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"error loading model: {e}\")\n",
    "        return False\n",
    "    \n",
    "    if not image_folder.exists() or not image_folder.is_dir():\n",
    "        print(f\"image folder does not exist or is not a directory: {image_folder}\")\n",
    "        return False\n",
    "    \n",
    "    # get all image files (case insensitive)\n",
    "    image_files = []\n",
    "    for ext in ['.jpg', '.jpeg']:\n",
    "        image_files.extend(image_folder.glob(f\"*{ext}\"))\n",
    "        image_files.extend(image_folder.glob(f\"*{ext.upper()}\"))\n",
    "    \n",
    "    if not image_files:\n",
    "        print(f\"no images found in {image_folder}\")\n",
    "        return False\n",
    "    \n",
    "    print(f\"found {len(image_files)} images\")\n",
    "    \n",
    "    total_detections = 0\n",
    "    processed_count = 0\n",
    "    \n",
    "    for img_path in image_files[:10]:  # test first 10 images\n",
    "        try:\n",
    "            image = cv2.imread(str(img_path))\n",
    "            if image is None:\n",
    "                print(f\"could not load image {img_path}\")\n",
    "                continue\n",
    "            \n",
    "            results = model(image, conf=conf_threshold)\n",
    "            \n",
    "            detections = 0\n",
    "            for result in results:\n",
    "                if hasattr(result, 'boxes') and result.boxes is not None:\n",
    "                    detections += len(result.boxes)\n",
    "            \n",
    "            total_detections += detections\n",
    "            processed_count += 1\n",
    "            \n",
    "            if detections > 0:\n",
    "                print(f\"{img_path.name}: {detections} detections\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"error processing {img_path.name}: {e}\")\n",
    "    \n",
    "    print(f\"summary: {total_detections} total detections in {processed_count} images\")\n",
    "    return True\n",
    "\n",
    "# test on multiple images\n",
    "if Path(\"Images\").exists():\n",
    "    test_multiple_images(\"Images\", model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Candy Detector Env",
   "language": "python",
   "name": "my_candy_detector"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
