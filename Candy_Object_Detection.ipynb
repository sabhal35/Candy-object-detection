{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2d2782c2-f544-4dd8-b96a-eec7b5aa3a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "directory: /Users/larasabha/Desktop/Candy-object-detection\n",
      "structure created\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import json\n",
    "import yaml\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "\n",
    "project_root = Path.cwd()\n",
    "print(f\"directory: {project_root}\")\n",
    "\n",
    "dirs_to_create = [\n",
    "    project_root / \"Images\",\n",
    "    project_root / \"Annotation_CSV_Files\",\n",
    "    project_root / \"labels\",\n",
    "    project_root / \"dataset\" / \"images\" / \"train\",\n",
    "    project_root / \"dataset\" / \"images\" / \"val\",\n",
    "    project_root / \"dataset\" / \"labels\" / \"train\",\n",
    "    project_root / \"dataset\" / \"labels\" / \"val\",\n",
    "    project_root / \"test_results\"\n",
    "]\n",
    "\n",
    "for directory in dirs_to_create:\n",
    "    directory.mkdir(parents=True, exist_ok=True)\n",
    "print(\"structure created\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "add2eb25-9f21-4030-8ce1-8638c00f6bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "organizing dataset files\n",
      "no archive folder found\n",
      "moved 0 images to /Users/larasabha/Desktop/Candy-object-detection/Images\n",
      "moved 0 CSV files to /Users/larasabha/Desktop/Candy-object-detection/Annotation_CSV_Files\n",
      "final counts: 528 images, 11 CSV files\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def organize_dataset_files(root_dir=project_root):\n",
    "    \"\"\"\n",
    "    Images -> Images/\n",
    "    CSV annotation files -> Annotation_CSV_Files/\n",
    "    \"\"\"\n",
    "    print(\"organizing dataset files\")\n",
    "\n",
    "    archive_folders = [d for d in root_dir.iterdir() if d.is_dir() and 'candy' in d.name.lower()]\n",
    "    if archive_folders:\n",
    "        archive_folder = archive_folders[0]\n",
    "        print(f\"found archive folder: {archive_folder}\")\n",
    "        source_img_folder = archive_folder / \"Images\"\n",
    "        source_csv_folder = archive_folder / \"annotation csv files\"\n",
    "    else:\n",
    "        print(\"no archive folder found\")\n",
    "        source_img_folder = root_dir / \"Images\"\n",
    "        source_csv_folder = root_dir / \"annotation csv files\"\n",
    "\n",
    "    dest_img_folder = root_dir / \"Images\"\n",
    "    dest_csv_folder = root_dir / \"Annotation_CSV_Files\"\n",
    "    \n",
    "    moved_images = 0\n",
    "    moved_csvs = 0\n",
    "\n",
    "    if source_img_folder.exists():\n",
    "        for file in source_img_folder.iterdir():\n",
    "            if file.suffix.lower() in ['.jpg', '.jpeg', '.JPG', '.JPEG', '.png', '.PNG']:\n",
    "                dst = dest_img_folder / file.name\n",
    "                if not dst.exists():\n",
    "                    file.rename(dst)  # move file\n",
    "                    moved_images += 1\n",
    "        print(f\"moved {moved_images} images to {dest_img_folder}\")\n",
    "    else:\n",
    "        print(f\"images folder not found at {source_img_folder}\")\n",
    "\n",
    "    if source_csv_folder.exists():\n",
    "        for file in source_csv_folder.iterdir():\n",
    "            if file.suffix.lower() == '.csv':\n",
    "                dst = dest_csv_folder / file.name\n",
    "                if not dst.exists():\n",
    "                    file.rename(dst)\n",
    "                    moved_csvs += 1\n",
    "        print(f\"moved {moved_csvs} CSV files to {dest_csv_folder}\")\n",
    "    else:\n",
    "        print(f\"CSV folder not found at {source_csv_folder}\")\n",
    "\n",
    "    final_images = len(list(dest_img_folder.glob(\"*.[jJ][pP][gG]\"))) + \\\n",
    "                   len(list(dest_img_folder.glob(\"*.[jJ][pP][eE][gG]\"))) + \\\n",
    "                   len(list(dest_img_folder.glob(\"*.png\")))\n",
    "\n",
    "    final_csvs = len(list(dest_csv_folder.glob(\"*.csv\")))\n",
    "\n",
    "    print(f\"final counts: {final_images} images, {final_csvs} CSV files\")\n",
    "    return final_images > 0 and final_csvs > 0\n",
    "\n",
    "organize_dataset_files(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "64690e28-70b0-4887-9725-96741b86f693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting CSV annotations to YOLO format\n",
      "found 11 CSV files\n",
      "loaded Candy_Project_1930-1981_csv.csv\n",
      "loaded Candy_Project_2039-2092_csv.csv\n",
      "loaded Candy_Project_2359-2415_csv.csv\n",
      "loaded Candy_Project_1982-2038_csv.csv\n",
      "loaded Candy_Project_2147-2197_csv.csv\n",
      "loaded Candy_Project_2468-2496_csv.csv\n",
      "loaded Candy_Project_2093-2146_csv.csv\n",
      "loaded Candy_Project_2304-2358_csv.csv\n",
      "loaded Candy_Project_2253-2303_csv.csv\n",
      "loaded Candy_Project_2416-2467_csv.csv\n",
      "loaded Candy_Project_2198-2252_csv.csv\n",
      "total annotations: 2113\n",
      "found 9 classes: ['100_Grand', '3_Musketeers', 'Baby_Ruth', 'Butterfingers', 'Crunch', 'Midnight_Milky_Way', 'Milky_Way', 'Snickers', 'Twix']\n",
      "created classes.txt\n",
      "converted 1 image-label pairs\n",
      "converted 2 image-label pairs\n",
      "converted 3 image-label pairs\n",
      "converted 4 image-label pairs\n",
      "converted 5 image-label pairs\n",
      "converted 6 image-label pairs\n",
      "converted 7 image-label pairs\n",
      "converted 8 image-label pairs\n",
      "converted 9 image-label pairs\n",
      "converted 10 image-label pairs\n",
      "converted 11 image-label pairs\n",
      "converted 12 image-label pairs\n",
      "converted 13 image-label pairs\n",
      "converted 14 image-label pairs\n",
      "converted 15 image-label pairs\n",
      "converted 16 image-label pairs\n",
      "converted 17 image-label pairs\n",
      "converted 18 image-label pairs\n",
      "converted 19 image-label pairs\n",
      "converted 20 image-label pairs\n",
      "converted 21 image-label pairs\n",
      "converted 22 image-label pairs\n",
      "converted 23 image-label pairs\n",
      "converted 24 image-label pairs\n",
      "converted 25 image-label pairs\n",
      "converted 26 image-label pairs\n",
      "converted 27 image-label pairs\n",
      "converted 28 image-label pairs\n",
      "converted 29 image-label pairs\n",
      "converted 30 image-label pairs\n",
      "converted 31 image-label pairs\n",
      "converted 32 image-label pairs\n",
      "converted 33 image-label pairs\n",
      "converted 34 image-label pairs\n",
      "converted 35 image-label pairs\n",
      "converted 36 image-label pairs\n",
      "converted 37 image-label pairs\n",
      "converted 38 image-label pairs\n",
      "converted 39 image-label pairs\n",
      "converted 40 image-label pairs\n",
      "converted 41 image-label pairs\n",
      "converted 42 image-label pairs\n",
      "converted 43 image-label pairs\n",
      "converted 44 image-label pairs\n",
      "converted 45 image-label pairs\n",
      "converted 46 image-label pairs\n",
      "converted 47 image-label pairs\n",
      "converted 48 image-label pairs\n",
      "converted 49 image-label pairs\n",
      "converted 50 image-label pairs\n",
      "converted 51 image-label pairs\n",
      "converted 52 image-label pairs\n",
      "converted 53 image-label pairs\n",
      "converted 54 image-label pairs\n",
      "converted 55 image-label pairs\n",
      "converted 56 image-label pairs\n",
      "converted 57 image-label pairs\n",
      "converted 58 image-label pairs\n",
      "converted 59 image-label pairs\n",
      "converted 60 image-label pairs\n",
      "converted 61 image-label pairs\n",
      "converted 62 image-label pairs\n",
      "converted 63 image-label pairs\n",
      "converted 64 image-label pairs\n",
      "converted 65 image-label pairs\n",
      "converted 66 image-label pairs\n",
      "converted 67 image-label pairs\n",
      "converted 68 image-label pairs\n",
      "converted 69 image-label pairs\n",
      "converted 70 image-label pairs\n",
      "converted 71 image-label pairs\n",
      "converted 72 image-label pairs\n",
      "converted 73 image-label pairs\n",
      "converted 74 image-label pairs\n",
      "converted 75 image-label pairs\n",
      "converted 76 image-label pairs\n",
      "converted 77 image-label pairs\n",
      "converted 78 image-label pairs\n",
      "converted 79 image-label pairs\n",
      "converted 80 image-label pairs\n",
      "converted 81 image-label pairs\n",
      "converted 82 image-label pairs\n",
      "converted 83 image-label pairs\n",
      "converted 84 image-label pairs\n",
      "converted 85 image-label pairs\n",
      "converted 86 image-label pairs\n",
      "converted 87 image-label pairs\n",
      "converted 88 image-label pairs\n",
      "converted 89 image-label pairs\n",
      "converted 90 image-label pairs\n",
      "converted 91 image-label pairs\n",
      "converted 92 image-label pairs\n",
      "converted 93 image-label pairs\n",
      "converted 94 image-label pairs\n",
      "converted 95 image-label pairs\n",
      "converted 96 image-label pairs\n",
      "converted 97 image-label pairs\n",
      "converted 98 image-label pairs\n",
      "converted 99 image-label pairs\n",
      "converted 100 image-label pairs\n",
      "converted 101 image-label pairs\n",
      "converted 102 image-label pairs\n",
      "converted 103 image-label pairs\n",
      "converted 104 image-label pairs\n",
      "converted 105 image-label pairs\n",
      "converted 106 image-label pairs\n",
      "converted 107 image-label pairs\n",
      "converted 108 image-label pairs\n",
      "converted 109 image-label pairs\n",
      "converted 110 image-label pairs\n",
      "converted 111 image-label pairs\n",
      "converted 112 image-label pairs\n",
      "converted 113 image-label pairs\n",
      "converted 114 image-label pairs\n",
      "converted 115 image-label pairs\n",
      "converted 116 image-label pairs\n",
      "converted 117 image-label pairs\n",
      "converted 118 image-label pairs\n",
      "converted 119 image-label pairs\n",
      "converted 120 image-label pairs\n",
      "converted 121 image-label pairs\n",
      "converted 122 image-label pairs\n",
      "converted 123 image-label pairs\n",
      "converted 124 image-label pairs\n",
      "converted 125 image-label pairs\n",
      "converted 126 image-label pairs\n",
      "converted 127 image-label pairs\n",
      "converted 128 image-label pairs\n",
      "converted 129 image-label pairs\n",
      "converted 130 image-label pairs\n",
      "converted 131 image-label pairs\n",
      "converted 132 image-label pairs\n",
      "converted 133 image-label pairs\n",
      "converted 134 image-label pairs\n",
      "converted 135 image-label pairs\n",
      "converted 136 image-label pairs\n",
      "converted 137 image-label pairs\n",
      "converted 138 image-label pairs\n",
      "converted 139 image-label pairs\n",
      "converted 140 image-label pairs\n",
      "converted 141 image-label pairs\n",
      "converted 142 image-label pairs\n",
      "converted 143 image-label pairs\n",
      "converted 144 image-label pairs\n",
      "converted 145 image-label pairs\n",
      "converted 146 image-label pairs\n",
      "converted 147 image-label pairs\n",
      "converted 148 image-label pairs\n",
      "converted 149 image-label pairs\n",
      "converted 150 image-label pairs\n",
      "converted 151 image-label pairs\n",
      "converted 152 image-label pairs\n",
      "converted 153 image-label pairs\n",
      "converted 154 image-label pairs\n",
      "converted 155 image-label pairs\n",
      "converted 156 image-label pairs\n",
      "converted 157 image-label pairs\n",
      "converted 158 image-label pairs\n",
      "converted 159 image-label pairs\n",
      "converted 160 image-label pairs\n",
      "converted 161 image-label pairs\n",
      "converted 162 image-label pairs\n",
      "converted 163 image-label pairs\n",
      "converted 164 image-label pairs\n",
      "converted 165 image-label pairs\n",
      "converted 166 image-label pairs\n",
      "converted 167 image-label pairs\n",
      "converted 168 image-label pairs\n",
      "converted 169 image-label pairs\n",
      "converted 170 image-label pairs\n",
      "converted 171 image-label pairs\n",
      "converted 172 image-label pairs\n",
      "converted 173 image-label pairs\n",
      "converted 174 image-label pairs\n",
      "converted 175 image-label pairs\n",
      "converted 176 image-label pairs\n",
      "converted 177 image-label pairs\n",
      "converted 178 image-label pairs\n",
      "converted 179 image-label pairs\n",
      "converted 180 image-label pairs\n",
      "converted 181 image-label pairs\n",
      "converted 182 image-label pairs\n",
      "converted 183 image-label pairs\n",
      "converted 184 image-label pairs\n",
      "converted 185 image-label pairs\n",
      "converted 186 image-label pairs\n",
      "converted 187 image-label pairs\n",
      "converted 188 image-label pairs\n",
      "converted 189 image-label pairs\n",
      "converted 190 image-label pairs\n",
      "converted 191 image-label pairs\n",
      "converted 192 image-label pairs\n",
      "converted 193 image-label pairs\n",
      "converted 194 image-label pairs\n",
      "converted 195 image-label pairs\n",
      "converted 196 image-label pairs\n",
      "converted 197 image-label pairs\n",
      "converted 198 image-label pairs\n",
      "converted 199 image-label pairs\n",
      "converted 200 image-label pairs\n",
      "converted 201 image-label pairs\n",
      "converted 202 image-label pairs\n",
      "converted 203 image-label pairs\n",
      "converted 204 image-label pairs\n",
      "converted 205 image-label pairs\n",
      "converted 206 image-label pairs\n",
      "converted 207 image-label pairs\n",
      "converted 208 image-label pairs\n",
      "converted 209 image-label pairs\n",
      "converted 210 image-label pairs\n",
      "converted 211 image-label pairs\n",
      "converted 212 image-label pairs\n",
      "converted 213 image-label pairs\n",
      "converted 214 image-label pairs\n",
      "converted 215 image-label pairs\n",
      "converted 216 image-label pairs\n",
      "converted 217 image-label pairs\n",
      "converted 218 image-label pairs\n",
      "converted 219 image-label pairs\n",
      "converted 220 image-label pairs\n",
      "converted 221 image-label pairs\n",
      "converted 222 image-label pairs\n",
      "converted 223 image-label pairs\n",
      "converted 224 image-label pairs\n",
      "converted 225 image-label pairs\n",
      "converted 226 image-label pairs\n",
      "converted 227 image-label pairs\n",
      "converted 228 image-label pairs\n",
      "converted 229 image-label pairs\n",
      "converted 230 image-label pairs\n",
      "converted 231 image-label pairs\n",
      "converted 232 image-label pairs\n",
      "converted 233 image-label pairs\n",
      "converted 234 image-label pairs\n",
      "converted 235 image-label pairs\n",
      "converted 236 image-label pairs\n",
      "converted 237 image-label pairs\n",
      "converted 238 image-label pairs\n",
      "converted 239 image-label pairs\n",
      "converted 240 image-label pairs\n",
      "converted 241 image-label pairs\n",
      "converted 242 image-label pairs\n",
      "converted 243 image-label pairs\n",
      "converted 244 image-label pairs\n",
      "converted 245 image-label pairs\n",
      "converted 246 image-label pairs\n",
      "converted 247 image-label pairs\n",
      "converted 248 image-label pairs\n",
      "converted 249 image-label pairs\n",
      "converted 250 image-label pairs\n",
      "converted 251 image-label pairs\n",
      "converted 252 image-label pairs\n",
      "converted 253 image-label pairs\n",
      "converted 254 image-label pairs\n",
      "converted 255 image-label pairs\n",
      "converted 256 image-label pairs\n",
      "converted 257 image-label pairs\n",
      "converted 258 image-label pairs\n",
      "converted 259 image-label pairs\n",
      "converted 260 image-label pairs\n",
      "converted 261 image-label pairs\n",
      "converted 262 image-label pairs\n",
      "converted 263 image-label pairs\n",
      "converted 264 image-label pairs\n",
      "converted 265 image-label pairs\n",
      "converted 266 image-label pairs\n",
      "converted 267 image-label pairs\n",
      "converted 268 image-label pairs\n",
      "converted 269 image-label pairs\n",
      "converted 270 image-label pairs\n",
      "converted 271 image-label pairs\n",
      "converted 272 image-label pairs\n",
      "converted 273 image-label pairs\n",
      "converted 274 image-label pairs\n",
      "converted 275 image-label pairs\n",
      "converted 276 image-label pairs\n",
      "converted 277 image-label pairs\n",
      "converted 278 image-label pairs\n",
      "converted 279 image-label pairs\n",
      "converted 280 image-label pairs\n",
      "converted 281 image-label pairs\n",
      "converted 282 image-label pairs\n",
      "converted 283 image-label pairs\n",
      "converted 284 image-label pairs\n",
      "converted 285 image-label pairs\n",
      "converted 286 image-label pairs\n",
      "converted 287 image-label pairs\n",
      "converted 288 image-label pairs\n",
      "converted 289 image-label pairs\n",
      "converted 290 image-label pairs\n",
      "converted 291 image-label pairs\n",
      "converted 292 image-label pairs\n",
      "converted 293 image-label pairs\n",
      "converted 294 image-label pairs\n",
      "converted 295 image-label pairs\n",
      "converted 296 image-label pairs\n",
      "converted 297 image-label pairs\n",
      "converted 298 image-label pairs\n",
      "converted 299 image-label pairs\n",
      "converted 300 image-label pairs\n",
      "converted 301 image-label pairs\n",
      "converted 302 image-label pairs\n",
      "converted 303 image-label pairs\n",
      "converted 304 image-label pairs\n",
      "converted 305 image-label pairs\n",
      "converted 306 image-label pairs\n",
      "converted 307 image-label pairs\n",
      "converted 308 image-label pairs\n",
      "converted 309 image-label pairs\n",
      "converted 310 image-label pairs\n",
      "converted 311 image-label pairs\n",
      "converted 312 image-label pairs\n",
      "converted 313 image-label pairs\n",
      "converted 314 image-label pairs\n",
      "converted 315 image-label pairs\n",
      "converted 316 image-label pairs\n",
      "converted 317 image-label pairs\n",
      "converted 318 image-label pairs\n",
      "converted 319 image-label pairs\n",
      "converted 320 image-label pairs\n",
      "converted 321 image-label pairs\n",
      "converted 322 image-label pairs\n",
      "converted 323 image-label pairs\n",
      "converted 324 image-label pairs\n",
      "converted 325 image-label pairs\n",
      "converted 326 image-label pairs\n",
      "converted 327 image-label pairs\n",
      "converted 328 image-label pairs\n",
      "converted 329 image-label pairs\n",
      "converted 330 image-label pairs\n",
      "converted 331 image-label pairs\n",
      "converted 332 image-label pairs\n",
      "converted 333 image-label pairs\n",
      "converted 334 image-label pairs\n",
      "converted 335 image-label pairs\n",
      "converted 336 image-label pairs\n",
      "converted 337 image-label pairs\n",
      "converted 338 image-label pairs\n",
      "converted 339 image-label pairs\n",
      "converted 340 image-label pairs\n",
      "converted 341 image-label pairs\n",
      "converted 342 image-label pairs\n",
      "converted 343 image-label pairs\n",
      "converted 344 image-label pairs\n",
      "converted 345 image-label pairs\n",
      "converted 346 image-label pairs\n",
      "converted 347 image-label pairs\n",
      "converted 348 image-label pairs\n",
      "converted 349 image-label pairs\n",
      "converted 350 image-label pairs\n",
      "converted 351 image-label pairs\n",
      "converted 352 image-label pairs\n",
      "converted 353 image-label pairs\n",
      "converted 354 image-label pairs\n",
      "converted 355 image-label pairs\n",
      "converted 356 image-label pairs\n",
      "converted 357 image-label pairs\n",
      "converted 358 image-label pairs\n",
      "converted 359 image-label pairs\n",
      "converted 360 image-label pairs\n",
      "converted 361 image-label pairs\n",
      "converted 362 image-label pairs\n",
      "converted 363 image-label pairs\n",
      "converted 364 image-label pairs\n",
      "converted 365 image-label pairs\n",
      "converted 366 image-label pairs\n",
      "converted 367 image-label pairs\n",
      "converted 368 image-label pairs\n",
      "converted 369 image-label pairs\n",
      "converted 370 image-label pairs\n",
      "converted 371 image-label pairs\n",
      "converted 372 image-label pairs\n",
      "converted 373 image-label pairs\n",
      "converted 374 image-label pairs\n",
      "converted 375 image-label pairs\n",
      "converted 376 image-label pairs\n",
      "converted 377 image-label pairs\n",
      "converted 378 image-label pairs\n",
      "converted 379 image-label pairs\n",
      "converted 380 image-label pairs\n",
      "converted 381 image-label pairs\n",
      "converted 382 image-label pairs\n",
      "converted 383 image-label pairs\n",
      "converted 384 image-label pairs\n",
      "converted 385 image-label pairs\n",
      "converted 386 image-label pairs\n",
      "converted 387 image-label pairs\n",
      "converted 388 image-label pairs\n",
      "converted 389 image-label pairs\n",
      "converted 390 image-label pairs\n",
      "converted 391 image-label pairs\n",
      "converted 392 image-label pairs\n",
      "converted 393 image-label pairs\n",
      "converted 394 image-label pairs\n",
      "converted 395 image-label pairs\n",
      "converted 396 image-label pairs\n",
      "converted 397 image-label pairs\n",
      "converted 398 image-label pairs\n",
      "converted 399 image-label pairs\n",
      "converted 400 image-label pairs\n",
      "converted 401 image-label pairs\n",
      "converted 402 image-label pairs\n",
      "converted 403 image-label pairs\n",
      "converted 404 image-label pairs\n",
      "converted 405 image-label pairs\n",
      "converted 406 image-label pairs\n",
      "converted 407 image-label pairs\n",
      "converted 408 image-label pairs\n",
      "converted 409 image-label pairs\n",
      "converted 410 image-label pairs\n",
      "converted 411 image-label pairs\n",
      "converted 412 image-label pairs\n",
      "converted 413 image-label pairs\n",
      "converted 414 image-label pairs\n",
      "converted 415 image-label pairs\n",
      "converted 416 image-label pairs\n",
      "converted 417 image-label pairs\n",
      "converted 418 image-label pairs\n",
      "converted 419 image-label pairs\n",
      "converted 420 image-label pairs\n",
      "converted 421 image-label pairs\n",
      "converted 422 image-label pairs\n",
      "converted 423 image-label pairs\n",
      "converted 424 image-label pairs\n",
      "converted 425 image-label pairs\n",
      "converted 426 image-label pairs\n",
      "converted 427 image-label pairs\n",
      "converted 428 image-label pairs\n",
      "converted 429 image-label pairs\n",
      "converted 430 image-label pairs\n",
      "converted 431 image-label pairs\n",
      "converted 432 image-label pairs\n",
      "converted 433 image-label pairs\n",
      "converted 434 image-label pairs\n",
      "converted 435 image-label pairs\n",
      "converted 436 image-label pairs\n",
      "converted 437 image-label pairs\n",
      "converted 438 image-label pairs\n",
      "converted 439 image-label pairs\n",
      "converted 440 image-label pairs\n",
      "converted 441 image-label pairs\n",
      "converted 442 image-label pairs\n",
      "converted 443 image-label pairs\n",
      "converted 444 image-label pairs\n",
      "converted 445 image-label pairs\n",
      "converted 446 image-label pairs\n",
      "converted 447 image-label pairs\n",
      "converted 448 image-label pairs\n",
      "converted 449 image-label pairs\n",
      "converted 450 image-label pairs\n",
      "converted 451 image-label pairs\n",
      "converted 452 image-label pairs\n",
      "converted 453 image-label pairs\n",
      "converted 454 image-label pairs\n",
      "converted 455 image-label pairs\n",
      "converted 456 image-label pairs\n",
      "converted 457 image-label pairs\n",
      "converted 458 image-label pairs\n",
      "converted 459 image-label pairs\n",
      "converted 460 image-label pairs\n",
      "converted 461 image-label pairs\n",
      "converted 462 image-label pairs\n",
      "converted 463 image-label pairs\n",
      "converted 464 image-label pairs\n",
      "converted 465 image-label pairs\n",
      "converted 466 image-label pairs\n",
      "converted 467 image-label pairs\n",
      "converted 468 image-label pairs\n",
      "converted 469 image-label pairs\n",
      "converted 470 image-label pairs\n",
      "converted 471 image-label pairs\n",
      "converted 472 image-label pairs\n",
      "converted 473 image-label pairs\n",
      "converted 474 image-label pairs\n",
      "converted 475 image-label pairs\n",
      "converted 476 image-label pairs\n",
      "converted 477 image-label pairs\n",
      "converted 478 image-label pairs\n",
      "converted 479 image-label pairs\n",
      "converted 480 image-label pairs\n",
      "converted 481 image-label pairs\n",
      "converted 482 image-label pairs\n",
      "converted 483 image-label pairs\n",
      "converted 484 image-label pairs\n",
      "converted 485 image-label pairs\n",
      "converted 486 image-label pairs\n",
      "converted 487 image-label pairs\n",
      "converted 488 image-label pairs\n",
      "converted 489 image-label pairs\n",
      "converted 490 image-label pairs\n",
      "converted 491 image-label pairs\n",
      "converted 492 image-label pairs\n",
      "converted 493 image-label pairs\n",
      "converted 494 image-label pairs\n",
      "converted 495 image-label pairs\n",
      "converted 496 image-label pairs\n",
      "converted 497 image-label pairs\n",
      "converted 498 image-label pairs\n",
      "converted 499 image-label pairs\n",
      "converted 500 image-label pairs\n",
      "converted 501 image-label pairs\n",
      "converted 502 image-label pairs\n",
      "converted 503 image-label pairs\n",
      "converted 504 image-label pairs\n",
      "converted 505 image-label pairs\n",
      "converted 506 image-label pairs\n",
      "converted 507 image-label pairs\n",
      "converted 508 image-label pairs\n",
      "converted 509 image-label pairs\n",
      "converted 510 image-label pairs\n",
      "converted 511 image-label pairs\n",
      "converted 512 image-label pairs\n",
      "converted 513 image-label pairs\n",
      "converted 514 image-label pairs\n",
      "converted 515 image-label pairs\n",
      "converted 516 image-label pairs\n",
      "converted 517 image-label pairs\n",
      "converted 518 image-label pairs\n",
      "converted 519 image-label pairs\n",
      "converted 520 image-label pairs\n",
      "converted 521 image-label pairs\n",
      "converted 522 image-label pairs\n",
      "converted 523 image-label pairs\n",
      "converted 524 image-label pairs\n",
      "converted 525 image-label pairs\n",
      "converted 526 image-label pairs\n",
      "converted 527 image-label pairs\n",
      "converted 528 image-label pairs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_csv_to_yolo(csv_folder=project_root / \"Annotation_CSV_Files\", \n",
    "                       image_folder=project_root / \"Images\", \n",
    "                       output_labels=project_root / \"labels\"):\n",
    "    \n",
    "    print(\"converting CSV annotations to YOLO format\")\n",
    "\n",
    "    # Make sure output directory exists\n",
    "    output_labels.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    if not csv_folder.exists():\n",
    "        print(f\"CSV folder not found: {csv_folder}\")\n",
    "        return False\n",
    "    \n",
    "    csv_files = list(csv_folder.glob(\"*.csv\"))\n",
    "    if not csv_files:\n",
    "        print(\"no CSV files found\")\n",
    "        return False\n",
    "    \n",
    "    print(f\"found {len(csv_files)} CSV files\")\n",
    "    \n",
    "    df_list = []\n",
    "    for csv_file in csv_files:\n",
    "        try:\n",
    "            df = pd.read_csv(csv_file)\n",
    "            df_list.append(df)\n",
    "            print(f\"loaded {csv_file.name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"error loading {csv_file.name}: {e}\")\n",
    "    \n",
    "    if not df_list:\n",
    "        print(\"no valid CSV files loaded\")\n",
    "        return False\n",
    "        \n",
    "    # combine all annotation dataframes into one    \n",
    "    df = pd.concat(df_list, ignore_index=True)\n",
    "    print(f\"total annotations: {len(df)}\")\n",
    "    \n",
    "    try:\n",
    "        # extract class names from JSON in region_attributes column\n",
    "        df['class'] = df['region_attributes'].apply(lambda x: json.loads(x)['candy_type'])\n",
    "        class_names = sorted(df['class'].unique())\n",
    "        class_to_id = {name: i for i, name in enumerate(class_names)}\n",
    "        \n",
    "        print(f\"found {len(class_names)} classes: {class_names}\")\n",
    "        \n",
    "        with open(project_root / \"classes.txt\", \"w\") as f:\n",
    "            for name in class_names:\n",
    "                f.write(name + \"\\n\")\n",
    "        \n",
    "        print(\"created classes.txt\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"error extracting classes: {e}\")\n",
    "        return False\n",
    "    \n",
    "    converted_count = 0\n",
    "    for filename in df['filename'].unique():\n",
    "        img_path = image_folder / filename\n",
    "        label_path = output_labels / (img_path.stem + \".txt\")\n",
    "        \n",
    "        if not img_path.exists():\n",
    "            print(f\"image not found: {img_path}\")\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            img = Image.open(img_path)\n",
    "            img_w, img_h = img.size  # get image width and height\n",
    "        except Exception as e:\n",
    "            print(f\"failed to open image {filename}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # save class names to classes.txt for YOLO training\n",
    "        with open(label_path, \"w\") as f:\n",
    "            rows = df[df['filename'] == filename]\n",
    "            for _, row in rows.iterrows():\n",
    "                try:\n",
    "                    # parse bounding box and label info from JSON\n",
    "                    shape = json.loads(row['region_shape_attributes'])\n",
    "                    label = json.loads(row['region_attributes'])['candy_type']\n",
    "                    class_id = class_to_id[label]\n",
    "\n",
    "                    # get bounding box coordinates and size\n",
    "                    x, y, w, h = shape['x'], shape['y'], shape['width'], shape['height']\n",
    "                    # convert to YOLO format (normalized center x, center y, width, height)\n",
    "                    # YOLO format requires relative coordinates [0,1] normalized by image size\n",
    "                    x_center = (x + w / 2) / img_w\n",
    "                    y_center = (y + h / 2) / img_h\n",
    "                    w_norm = w / img_w\n",
    "                    h_norm = h / img_h\n",
    "                    \n",
    "                    f.write(f\"{class_id} {x_center:.6f} {y_center:.6f} {w_norm:.6f} {h_norm:.6f}\\n\")\n",
    "                except Exception as e:\n",
    "                    print(f\"skipping annotation in {filename}: {e}\")\n",
    "                    continue\n",
    "        \n",
    "        converted_count += 1\n",
    "    \n",
    "        print(f\"converted {converted_count} image-label pairs\")\n",
    "    return True\n",
    "\n",
    "# run\n",
    "convert_csv_to_yolo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "29d46b27-bb19-4831-bde4-72f464e42475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating train/validation split\n",
      "found 528 images and 528 labels\n",
      "found 528 matching image-label pairs\n",
      "split: 475 training, 53 validation\n",
      "successfully created 475 training and 53 validation pairs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_train_val_split(train_ratio=0.9, root_dir=project_root):\n",
    "    \"\"\"train/validation split for YOLO training\"\"\"\n",
    "    \n",
    "    print(\"creating train/validation split\")\n",
    "    \n",
    "    # paths\n",
    "    images_dir = root_dir / \"Images\"\n",
    "    labels_dir = root_dir / \"labels\"\n",
    "    train_img_dir = root_dir / \"dataset/images/train\"\n",
    "    val_img_dir = root_dir / \"dataset/images/val\"\n",
    "    train_label_dir = root_dir / \"dataset/labels/train\"\n",
    "    val_label_dir = root_dir / \"dataset/labels/val\"\n",
    "    \n",
    "    # check if source directories exist\n",
    "    if not images_dir.exists() or not labels_dir.exists():\n",
    "        print(\"images or labels directory not found\")\n",
    "        return False\n",
    "\n",
    "    # collect image files\n",
    "    image_files = [f.name for f in images_dir.glob(\"*\") if f.suffix.lower() in [\".jpg\", \".jpeg\", \".JPG\", \".JPEG\", \".png\", \".PNG\"]]\n",
    "\n",
    "    # collect label files\n",
    "    label_files = [f.name for f in labels_dir.glob(\"*.txt\")]\n",
    "\n",
    "    print(f\"found {len(image_files)} images and {len(label_files)} labels\")\n",
    "\n",
    "    # match image label pairs by filename\n",
    "    matched_pairs = []\n",
    "    for img_file in image_files:\n",
    "        base_name = Path(img_file).stem\n",
    "        label_file = base_name + \".txt\"\n",
    "        if label_file in label_files:\n",
    "            matched_pairs.append((img_file, label_file))\n",
    "\n",
    "    print(f\"found {len(matched_pairs)} matching image-label pairs\")\n",
    "\n",
    "    if len(matched_pairs) == 0:\n",
    "        print(\"no matching pairs found\")\n",
    "        return False\n",
    "\n",
    "    # shuffle and split\n",
    "    random.seed(42)\n",
    "    random.shuffle(matched_pairs)\n",
    "\n",
    "    split_idx = int(len(matched_pairs) * train_ratio)\n",
    "    train_pairs = matched_pairs[:split_idx]\n",
    "    val_pairs = matched_pairs[split_idx:]\n",
    "\n",
    "    print(f\"split: {len(train_pairs)} training, {len(val_pairs)} validation\")\n",
    "\n",
    "    # copy training files\n",
    "    train_success = 0\n",
    "    val_success = 0\n",
    "\n",
    "    for img_file, label_file in train_pairs:\n",
    "        try:\n",
    "            shutil.copy2(images_dir / img_file, train_img_dir / img_file)\n",
    "            shutil.copy2(labels_dir / label_file, train_label_dir / label_file)\n",
    "            train_success += 1\n",
    "        except Exception as e:\n",
    "            print(f\"failed to copy training pair {img_file}: {e}\")\n",
    "\n",
    "    # copy validation files\n",
    "    for img_file, label_file in val_pairs:\n",
    "        try:\n",
    "            shutil.copy2(images_dir / img_file, val_img_dir / img_file)\n",
    "            shutil.copy2(labels_dir / label_file, val_label_dir / label_file)\n",
    "            val_success += 1\n",
    "        except Exception as e:\n",
    "            print(f\"failed to copy validation pair {img_file}: {e}\")\n",
    "\n",
    "    print(f\"successfully created {train_success} training and {val_success} validation pairs\")\n",
    "    return True\n",
    "\n",
    "# run the split\n",
    "create_train_val_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f61b64d7-77d6-4405-9e24-ffec8781bf26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating data.yaml\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'root_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 36\u001b[39m\n\u001b[32m     33\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m# run the function\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m \u001b[43mcreate_data_yaml\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 7\u001b[39m, in \u001b[36mcreate_data_yaml\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mcreating data.yaml\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# path to the file that contains class names\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m classes_file = \u001b[43mroot_dir\u001b[49m / \u001b[33m\"\u001b[39m\u001b[33mclasses.txt\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# try reading class names from classes.txt\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[31mNameError\u001b[39m: name 'root_dir' is not defined"
     ]
    }
   ],
   "source": [
    "def create_data_yaml(root_dir):\n",
    "    \"\"\"create data.yaml file\"\"\"\n",
    "    \n",
    "    print(\"creating data.yaml\")\n",
    "    \n",
    "    # path to the file that contains class names\n",
    "    classes_file = root_dir / \"classes.txt\"\n",
    "    \n",
    "    # try reading class names from classes.txt\n",
    "    try:\n",
    "        with open(classes_file, \"r\") as f:\n",
    "            class_names = [line.strip() for line in f.readlines() if line.strip()]\n",
    "    except FileNotFoundError:\n",
    "        print(f\"{classes_file} not found!\")\n",
    "        return False\n",
    "\n",
    "    # prepare dictionary with dataset info\n",
    "    data_content = {\n",
    "        'path': str(root_dir / 'dataset'),       # path for YOLO training\n",
    "        'train': 'images/train',\n",
    "        'val': 'images/val',\n",
    "        'nc': len(class_names),                  # # of classes\n",
    "        'names': class_names                     # list of class names\n",
    "    }\n",
    "\n",
    "    # write the YAML\n",
    "    output_yaml = root_dir / 'data.yaml'\n",
    "    with open(output_yaml, 'w') as f:\n",
    "        yaml.dump(data_content, f, default_flow_style=False, sort_keys=False)\n",
    "\n",
    "    print(f\"created data.yaml with {len(class_names)} classes\")\n",
    "    print(f\"classes: {class_names}\")\n",
    "    return True\n",
    "\n",
    "# run the function\n",
    "create_data_yaml()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e9a30d-7197-4cb6-9cc1-f207f111452c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting model training\n",
      "New https://pypi.org/project/ultralytics/8.3.169 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.167 ðŸš€ Python-3.12.2 torch-2.7.1 CPU (Apple M1 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/Users/larasabha/Desktop/Candy-object-detection/data.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=candy_detection10, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/Users/larasabha/PycharmProjects/Candy-object-detection/runs/detect/candy_detection10, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=9\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    753067  ultralytics.nn.modules.head.Detect           [9, [64, 128, 256]]           \n",
      "Model summary: 129 layers, 3,012,603 parameters, 3,012,587 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 3045.3Â±1443.4 MB/s, size: 5718.6 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/larasabha/Desktop/Candy-object-detection/dataset/labels/train.cache... 475 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 475/475 [00:00<?, ?it/s]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 5270.4Â±1310.7 MB/s, size: 5856.3 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/larasabha/Desktop/Candy-object-detection/dataset/labels/val.cache... 53 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 53/53 [00:00<?, ?it/s]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to /Users/larasabha/PycharmProjects/Candy-object-detection/runs/detect/candy_detection10/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000769, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1m/Users/larasabha/PycharmProjects/Candy-object-detection/runs/detect/candy_detection10\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/20         0G     0.7768      3.222       1.09         78        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [03:33<00:00,  7.11s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         53        212     0.0174          1      0.311      0.291\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "       2/20         0G     0.6932      2.037      1.043        111        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [03:29<00:00,  6.97s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         53        212      0.757      0.553      0.594       0.55\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "       3/20         0G     0.6505      1.237      1.043         85        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [03:25<00:00,  6.85s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         53        212       0.58      0.748      0.751      0.678\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "       4/20         0G     0.6026     0.9324      1.006        100        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [03:26<00:00,  6.88s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         53        212      0.941      0.842      0.954      0.881\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "       5/20         0G     0.5798     0.8182      1.001        101        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [03:28<00:00,  6.95s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         53        212      0.975      0.985      0.995      0.933\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "       6/20         0G      0.567     0.7597     0.9891        125        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [03:26<00:00,  6.89s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         53        212      0.987      0.995      0.995      0.922\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "       7/20         0G     0.5725      0.729      0.985         90        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [03:27<00:00,  6.91s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         53        212      0.979      0.992      0.995      0.941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/20         0G     0.5292     0.6688     0.9588         97        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [03:28<00:00,  6.94s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         53        212      0.995      0.996      0.995      0.947\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "       9/20         0G     0.5195      0.647     0.9631         83        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [03:27<00:00,  6.91s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         53        212      0.994      0.996      0.995      0.943\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      10/20         0G     0.5058     0.6281     0.9521        102        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [03:26<00:00,  6.88s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         53        212      0.985      0.996      0.995      0.947\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      11/20         0G     0.3748     0.5995     0.8618         44        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [16:22<00:00, 32.77s/it] \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:53<00:00, 26.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         53        212      0.984      0.985      0.995      0.953\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      12/20         0G     0.3506     0.5444     0.8418         44        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [38:49<00:00, 77.66s/it] \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         53        212      0.995      0.999      0.995      0.945\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      13/20         0G     0.3423     0.5252     0.8441         44        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [03:31<00:00,  7.05s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         53        212      0.995      0.999      0.995      0.946\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      14/20         0G     0.3354     0.4953     0.8388         44        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [03:29<00:00,  7.00s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         53        212      0.995          1      0.995      0.953\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      15/20         0G       0.33     0.4716      0.837         44        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [03:31<00:00,  7.04s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         53        212      0.996          1      0.995      0.958\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      16/20         0G     0.3273     0.4608     0.8397         44        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [03:31<00:00,  7.04s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         53        212      0.996      0.998      0.995      0.949\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      17/20         0G     0.3196     0.4429      0.832         44        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [03:31<00:00,  7.05s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         53        212      0.996      0.997      0.995      0.954\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      18/20         0G     0.3164     0.4332     0.8283         44        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [03:29<00:00,  6.99s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "def train_model(epochs=100, img_size=640, batch_size=16, root_dir=project_root):\n",
    "    \"\"\"train YOLOv8 model\"\"\"\n",
    "    \n",
    "    print(\"starting model training\")\n",
    "    \n",
    "    # path to data.yaml\n",
    "    data_yaml = root_dir / \"data.yaml\"\n",
    "    \n",
    "    # check if data.yaml exists\n",
    "    if not data_yaml.exists():\n",
    "        print(f\"{data_yaml} not found\")\n",
    "        return False\n",
    "\n",
    "    try:\n",
    "        # load base model\n",
    "        model = YOLO('yolov8n.pt')  # will auto download\n",
    "\n",
    "        # train the model with provided parameters\n",
    "        results = model.train(\n",
    "            data=str(data_yaml),        # path to data.yaml\n",
    "            epochs=epochs,              # # of training epochs\n",
    "            imgsz=img_size,             # image input size\n",
    "            batch=batch_size,           # batch size\n",
    "            name='candy_detection',     # training run name\n",
    "            patience=20,                # early stopping patience\n",
    "            save=True,                  # save final weights\n",
    "            plots=True                  # save training plots\n",
    "        )\n",
    "\n",
    "        print(\"training completed\")\n",
    "        print(f\"results saved in: runs/detect/candy_detection/\")\n",
    "\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"training failed: {e}\")\n",
    "        return False\n",
    "\n",
    "train_model(epochs=20)  # reduced epochs for faster training -> change to 100 for complete training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1df3ee6f-e90d-41fb-9424-35fac6b816a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found model: runs/detect/train2/weights/best.pt\n"
     ]
    }
   ],
   "source": [
    "# check for existing trained model\n",
    "def find_best_model():\n",
    "    \"\"\"find the best trained model\"\"\"\n",
    "    \n",
    "   # list of common paths\n",
    "    possible_paths = [\n",
    "        \"runs/detect/candy_detection/weights/best.pt\",\n",
    "        \"runs/detect/train/weights/best.pt\",\n",
    "        \"runs/detect/train2/weights/best.pt\",\n",
    "        \"best.pt\",\n",
    "        \"my_model.pt\"\n",
    "    ]\n",
    "    \n",
    "    # search for the first valid path\n",
    "    for path in possible_paths:\n",
    "        if os.path.exists(path):\n",
    "            print(f\"Found model: {path}\")\n",
    "            return path  # return the first match\n",
    "\n",
    "    print(\"no trained model found\")\n",
    "    return None\n",
    "\n",
    "# path for best model\n",
    "model_path = find_best_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9c7375d8-cc78-4bcc-9e33-2d45f1a289f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing detection on: /Users/larasabha/Desktop/image.jpg\n",
      "model loaded: runs/detect/train2/weights/best.pt\n",
      "image size: 225x225\n",
      "\n",
      "0: 640x640 1 Milky_Way, 1 Snickers, 56.5ms\n",
      "Speed: 1.2ms preprocess, 56.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "found 2 detections:\n",
      "  1. Snickers (0.98)\n",
      "  2. Milky_Way (0.72)\n",
      "result saved to: test_results/detection_result.jpg\n"
     ]
    }
   ],
   "source": [
    "def test_single_image(image_path, model_path=None, conf_threshold=0.5):\n",
    "    \"\"\"test detection on a single image\"\"\"\n",
    "    \n",
    "    print(f\"testing detection on: {image_path}\")\n",
    "    \n",
    "    # find model if not provided\n",
    "    if model_path is None:\n",
    "        model_path = find_best_model()\n",
    "        if model_path is None:\n",
    "            return False\n",
    "    \n",
    "    # check image exists\n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"image not found: {image_path}\")\n",
    "        return False\n",
    "    \n",
    "    # load model\n",
    "    try:\n",
    "        model = YOLO(model_path)\n",
    "        print(f\"model loaded: {model_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"error loading model: {e}\")\n",
    "        return False\n",
    "    \n",
    "    # load image\n",
    "    try:\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            print(\"could not load image\")\n",
    "            return False\n",
    "        \n",
    "        height, width = image.shape[:2]\n",
    "        print(f\"image size: {width}x{height}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"error loading image: {e}\")\n",
    "        return False\n",
    "    \n",
    "    # run detection\n",
    "    try:\n",
    "        results = model(image, conf=conf_threshold)\n",
    "        \n",
    "        detections = []\n",
    "        result_image = image.copy()\n",
    "        \n",
    "        for result in results:\n",
    "            if hasattr(result, 'boxes') and result.boxes is not None:\n",
    "                for box in result.boxes:\n",
    "                    if box.xyxy is None or box.conf is None or box.cls is None:\n",
    "                        continue\n",
    "                    \n",
    "                    # get detection\n",
    "                    x1, y1, x2, y2 = map(int, box.xyxy[0].cpu().numpy())\n",
    "                    conf = float(box.conf[0].cpu().numpy())\n",
    "                    class_id = int(box.cls[0].cpu().numpy())\n",
    "                    class_name = model.names.get(class_id, f\"Class_{class_id}\")\n",
    "                    \n",
    "                    detections.append({\n",
    "                        'class': class_name,\n",
    "                        'confidence': conf,\n",
    "                        'box': [x1, y1, x2, y2]\n",
    "                    })\n",
    "                    \n",
    "                    # draw on image\n",
    "                    color = (0, 255, 0)  # Green\n",
    "                    cv2.rectangle(result_image, (x1, y1), (x2, y2), color, 2)\n",
    "                    cv2.putText(result_image, f\"{class_name} {conf:.2f}\", \n",
    "                              (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                              0.6, color, 2)\n",
    "        \n",
    "        print(f\"found {len(detections)} detections:\")\n",
    "        for i, det in enumerate(detections):\n",
    "            print(f\"  {i+1}. {det['class']} ({det['confidence']:.2f})\")\n",
    "\n",
    "        os.makedirs(\"test_results\", exist_ok=True)\n",
    "\n",
    "        # save result\n",
    "        output_path = Path(\"test_results\") / \"detection_result.jpg\"\n",
    "        cv2.imwrite(str(output_path), result_image)\n",
    "        print(f\"result saved to: {output_path.resolve()}\")\n",
    "        \n",
    "        return True, detections, result_image\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"error during detection: {e}\")\n",
    "        return False, [], None\n",
    "\n",
    "# test with desktop image (change path as needed)\n",
    "desktop_image = str(Path.home() / \"Desktop\" / \"image.jpg\")\n",
    "if os.path.exists(desktop_image):\n",
    "    test_single_image(desktop_image, model_path)\n",
    "else:\n",
    "    print(f\"no test image found at {desktop_image}\")\n",
    "    print(\"place an image named 'image.jpg' on your Desktop to test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7135d21e-80e9-4049-809d-6f874fdbceae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing detection on images in: Images\n",
      "model loaded: runs/detect/train2/weights/best.pt\n",
      "found 528 images\n",
      "\n",
      "0: 480x640 1 Butterfingers, 1 Midnight_Milky_Way, 1 Snickers, 1 Twix, 55.6ms\n",
      "Speed: 5.6ms preprocess, 55.6ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "IMG_2165.JPG: 4 detections\n",
      "\n",
      "0: 480x640 1 3_Musketeers, 1 Butterfingers, 1 Midnight_Milky_Way, 1 Snickers, 46.5ms\n",
      "Speed: 2.8ms preprocess, 46.5ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "IMG_2171.JPG: 4 detections\n",
      "\n",
      "0: 480x640 1 Butterfingers, 1 Milky_Way, 1 Snickers, 1 Twix, 50.2ms\n",
      "Speed: 2.7ms preprocess, 50.2ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "IMG_2159.JPG: 4 detections\n",
      "\n",
      "0: 480x640 1 Crunch, 1 Milky_Way, 1 Snickers, 1 Twix, 45.6ms\n",
      "Speed: 2.2ms preprocess, 45.6ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "IMG_2398.JPG: 4 detections\n",
      "\n",
      "0: 480x640 1 Crunch, 1 Midnight_Milky_Way, 1 Snickers, 1 Twix, 50.7ms\n",
      "Speed: 2.4ms preprocess, 50.7ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "IMG_2401.JPG: 4 detections\n",
      "\n",
      "0: 480x640 1 100_Grand, 1 Crunch, 1 Milky_Way, 1 Twix, 49.2ms\n",
      "Speed: 3.3ms preprocess, 49.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "IMG_2367.JPG: 4 detections\n",
      "\n",
      "0: 480x640 1 100_Grand, 1 Crunch, 1 Midnight_Milky_Way, 1 Twix, 43.9ms\n",
      "Speed: 2.2ms preprocess, 43.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "IMG_2373.JPG: 4 detections\n",
      "\n",
      "0: 480x640 1 Crunch, 1 Midnight_Milky_Way, 1 Milky_Way, 1 Snickers, 45.7ms\n",
      "Speed: 2.5ms preprocess, 45.7ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "IMG_2415.JPG: 4 detections\n",
      "\n",
      "0: 480x640 1 Crunch, 1 Midnight_Milky_Way, 1 Milky_Way, 1 Twix, 45.7ms\n",
      "Speed: 2.0ms preprocess, 45.7ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "IMG_2429.JPG: 4 detections\n",
      "\n",
      "0: 480x640 1 100_Grand, 1 Baby_Ruth, 1 Crunch, 1 Midnight_Milky_Way, 51.9ms\n",
      "Speed: 3.1ms preprocess, 51.9ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "IMG_2213.JPG: 4 detections\n",
      "summary: 40 total detections in 10 images\n"
     ]
    }
   ],
   "source": [
    "def test_multiple_images(image_folder=\"Images\", model_path=None, conf_threshold=0.5):\n",
    "    \"\"\"test detection on multiple images\"\"\"\n",
    "    \n",
    "    image_folder = Path(image_folder)\n",
    "    \n",
    "    print(f\"testing detection on images in: {image_folder}\")\n",
    "    \n",
    "    if model_path is None:\n",
    "        model_path = find_best_model()\n",
    "        if model_path is None:\n",
    "            return False\n",
    "    \n",
    "    # load model\n",
    "    try:\n",
    "        model = YOLO(model_path)\n",
    "        print(f\"model loaded: {model_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"error loading model: {e}\")\n",
    "        return False\n",
    "    \n",
    "    if not image_folder.exists() or not image_folder.is_dir():\n",
    "        print(f\"image folder does not exist or is not a directory: {image_folder}\")\n",
    "        return False\n",
    "    \n",
    "    # get all image files (case insensitive)\n",
    "    image_files = []\n",
    "    for ext in ['.jpg', '.jpeg']:\n",
    "        image_files.extend(image_folder.glob(f\"*{ext}\"))\n",
    "        image_files.extend(image_folder.glob(f\"*{ext.upper()}\"))\n",
    "    \n",
    "    if not image_files:\n",
    "        print(f\"no images found in {image_folder}\")\n",
    "        return False\n",
    "    \n",
    "    print(f\"found {len(image_files)} images\")\n",
    "    \n",
    "    total_detections = 0\n",
    "    processed_count = 0\n",
    "    \n",
    "    for img_path in image_files[:10]:  # test first 10 images\n",
    "        try:\n",
    "            image = cv2.imread(str(img_path))\n",
    "            if image is None:\n",
    "                print(f\"could not load image {img_path}\")\n",
    "                continue\n",
    "            \n",
    "            results = model(image, conf=conf_threshold)\n",
    "            \n",
    "            detections = 0\n",
    "            for result in results:\n",
    "                if hasattr(result, 'boxes') and result.boxes is not None:\n",
    "                    detections += len(result.boxes)\n",
    "            \n",
    "            total_detections += detections\n",
    "            processed_count += 1\n",
    "            \n",
    "            if detections > 0:\n",
    "                print(f\"{img_path.name}: {detections} detections\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"error processing {img_path.name}: {e}\")\n",
    "    \n",
    "    print(f\"summary: {total_detections} total detections in {processed_count} images\")\n",
    "    return True\n",
    "\n",
    "# test on multiple images\n",
    "if Path(\"Images\").exists():\n",
    "    test_multiple_images(\"Images\", model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Candy Detector Env",
   "language": "python",
   "name": "my_candy_detector"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
