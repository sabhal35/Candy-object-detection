{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2d2782c2-f544-4dd8-b96a-eec7b5aa3a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "directory: /Users/larasabha/Desktop/Candy-object-detection\n",
      "structure created\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import random\n",
    "import shutil\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import yaml\n",
    "import json\n",
    "\n",
    "project_root = Path.cwd()\n",
    "print(f\"directory: {project_root}\")\n",
    "\n",
    "dirs_to_create = [\n",
    "    project_root / \"Images\",\n",
    "    project_root / \"Annotation_CSV_Files\",\n",
    "    project_root / \"labels\",\n",
    "    project_root / \"dataset\" / \"images\" / \"train\",\n",
    "    project_root / \"dataset\" / \"images\" / \"val\",\n",
    "    project_root / \"dataset\" / \"labels\" / \"train\",\n",
    "    project_root / \"dataset\" / \"labels\" / \"val\",\n",
    "    project_root / \"test_results\"\n",
    "]\n",
    "\n",
    "for directory in dirs_to_create:\n",
    "    directory.mkdir(parents=True, exist_ok=True)\n",
    "print(\"structure created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "eb0ea8a6-73d8-4cfb-b22e-b6ca575d9d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_csv_data(csv_folder=project_root / \"Annotation_CSV_Files\"):\n",
    "    \"\"\"analyze CSV data to understand the class distribution and format\"\"\"\n",
    "    \n",
    "    if not csv_folder.exists():\n",
    "        print(f\"CSV folder not found: {csv_folder}\")\n",
    "        return False\n",
    "    \n",
    "    csv_files = list(csv_folder.glob(\"*.csv\"))\n",
    "    if not csv_files:\n",
    "        print(\"no CSV files found\")\n",
    "        return False\n",
    "    \n",
    "    all_classes = set()\n",
    "    total_annotations = 0\n",
    "    class_counts = Counter()\n",
    "    \n",
    "    for csv_file in csv_files:\n",
    "        try:\n",
    "            df = pd.read_csv(csv_file)\n",
    "            if df.empty:\n",
    "                continue\n",
    "                \n",
    "            print(f\"\\nanalyzing {csv_file.name}:\")\n",
    "            print(f\"  columns: {list(df.columns)}\")\n",
    "            print(f\"  rows: {len(df)}\")\n",
    "            \n",
    "            # sample few region_attributes to understand format\n",
    "            if 'region_attributes' in df.columns:\n",
    "                print(\"  sample region_attributes:\")\n",
    "                for i, attr in enumerate(df['region_attributes'].head(3)):\n",
    "                    try:\n",
    "                        parsed = json.loads(attr)\n",
    "                        candy_type = parsed.get('candy_type', 'Unknown')\n",
    "                        normalized = normalize_class_name(candy_type)\n",
    "                        print(f\"    {i+1}. raw: '{candy_type}' -> normalized: '{normalized}'\")\n",
    "                        \n",
    "                        all_classes.add(normalized)\n",
    "                        class_counts[normalized] += 1\n",
    "                        total_annotations += 1\n",
    "                    except Exception as e:\n",
    "                        print(f\"    {i+1}, error parsing: {attr} - {e}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"error reading {csv_file.name}: {e}\")\n",
    "    \n",
    "    print(f\"total annotations: {total_annotations}\")\n",
    "    print(f\"unique classes found: {len(all_classes)}\")\n",
    "    print(f\"classes: {sorted(all_classes)}\")\n",
    "    \n",
    "    print(f\"\\nclass distribution:\")\n",
    "    for class_name, count in class_counts.most_common():\n",
    "        percentage = count / total_annotations * 100 if total_annotations > 0 else 0\n",
    "        print(f\"  {class_name}: {count} ({percentage:.1f}%)\")\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "add2eb25-9f21-4030-8ce1-8638c00f6bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def organize_dataset_files(root_dir=project_root):\n",
    "    \"\"\"\n",
    "    Images -> Images/\n",
    "    CSV annotation files -> Annotation_CSV_Files/\n",
    "    \"\"\"\n",
    "    print(\"organizing dataset files\")\n",
    "\n",
    "    archive_folders = [d for d in root_dir.iterdir() if d.is_dir() and 'candy' in d.name.lower()]\n",
    "    if archive_folders:\n",
    "        archive_folder = archive_folders[0]\n",
    "        print(f\"found archive folder: {archive_folder}\")\n",
    "        source_img_folder = archive_folder / \"Images\"\n",
    "        source_csv_folder = archive_folder / \"Annotation CSV Files\"\n",
    "    else:\n",
    "        print(\"no archive folder found\")\n",
    "        source_img_folder = root_dir / \"Images\"\n",
    "        source_csv_folder = root_dir / \"Annotation CSV Files\"\n",
    "\n",
    "    dest_img_folder = root_dir / \"Images\"\n",
    "    dest_csv_folder = root_dir / \"Annotation_CSV_Files\"\n",
    "    \n",
    "    moved_images = 0\n",
    "    moved_csvs = 0\n",
    "\n",
    "    if source_img_folder.exists():\n",
    "        for file in source_img_folder.iterdir():\n",
    "            if file.suffix.lower() in ['.jpg', '.jpeg', '.JPG', '.JPEG', '.png', '.PNG']:\n",
    "                dst = dest_img_folder / file.name\n",
    "                if not dst.exists():\n",
    "                    file.rename(dst)\n",
    "                    moved_images += 1\n",
    "        print(f\"moved {moved_images} images to {dest_img_folder}\")\n",
    "    else:\n",
    "        print(f\"images folder not found at {source_img_folder}\")\n",
    "\n",
    "    if source_csv_folder.exists():\n",
    "        for file in source_csv_folder.iterdir():\n",
    "            if file.suffix.lower() == '.csv':\n",
    "                dst = dest_csv_folder / file.name\n",
    "                if not dst.exists():\n",
    "                    file.rename(dst)\n",
    "                    moved_csvs += 1\n",
    "        print(f\"moved {moved_csvs} CSV files to {dest_csv_folder}\")\n",
    "    else:\n",
    "        print(f\"CSV folder not found at {source_csv_folder}\")\n",
    "\n",
    "    final_images = len(list(dest_img_folder.glob(\"*.[jJ][pP][gG]\"))) + \\\n",
    "                   len(list(dest_img_folder.glob(\"*.[jJ][pP][eE][gG]\"))) + \\\n",
    "                   len(list(dest_img_folder.glob(\"*.png\")))\n",
    "\n",
    "    final_csvs = len(list(dest_csv_folder.glob(\"*.csv\")))\n",
    "\n",
    "    print(f\"final counts: {final_images} images, {final_csvs} CSV files\")\n",
    "    return final_images > 0 and final_csvs > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "45e2d61e-543d-4d79-a99a-96c7a457658e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_class_name(class_name):\n",
    "    \"\"\"normalize class names to be more consistent\"\"\"\n",
    "    \n",
    "    if not class_name or class_name == '':\n",
    "        return 'Unknown'\n",
    "    \n",
    "    # convert to lowercase and remove extra spaces\n",
    "    normalized = class_name.lower().strip()\n",
    "    \n",
    "    # define mapping for common variations based on your actual CSV data\n",
    "    name_mapping = {\n",
    "        # actual classes from CSV\n",
    "        'crunch': 'Crunch',\n",
    "        'baby_ruth': 'Baby_Ruth',\n",
    "        'babyruth': 'Baby_Ruth', \n",
    "        'baby ruth': 'Baby_Ruth',\n",
    "        'butterfingers': 'Butterfinger',\n",
    "        'butterfinger': 'Butterfinger',\n",
    "        '3_musketeers': '3_Musketeers',\n",
    "        '3 musketeers': '3_Musketeers',\n",
    "        'three musketeers': '3_Musketeers',\n",
    "        'milky_way': 'Milky_Way',\n",
    "        'milky way': 'Milky_Way',\n",
    "        'milkyway': 'Milky_Way',\n",
    "        \n",
    "        # additional common variations\n",
    "        'snickers': 'Snickers',\n",
    "        'twix': 'Twix',\n",
    "        '100 grand': '100_Grand',\n",
    "        '100grand': '100_Grand',\n",
    "        '100_grand': '100_Grand',\n",
    "        'midnight milky way': 'Midnight_Milky_Way',\n",
    "        'midnight_milky_way': 'Midnight_Milky_Way',\n",
    "        'unknown': 'Unknown'\n",
    "    }\n",
    "    \n",
    "    return name_mapping.get(normalized, class_name.replace(' ', '_'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2ac677f3-0d9e-4d49-a43d-331cef026b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_non_overlapping_boxes(existing_boxes, img_w, img_h, num_boxes=3, min_size=0.15, max_size=0.3):\n",
    "    new_boxes = []\n",
    "    max_attempts = 50\n",
    "    \n",
    "    for _ in range(num_boxes):\n",
    "        for attempt in range(max_attempts):\n",
    "            # random\n",
    "            w_norm = random.uniform(min_size, max_size)\n",
    "            h_norm = random.uniform(min_size, max_size)\n",
    "            \n",
    "            # box stays within image bounds\n",
    "            x_center = random.uniform(w_norm/2, 1 - w_norm/2)\n",
    "            y_center = random.uniform(h_norm/2, 1 - h_norm/2)\n",
    "            \n",
    "            # overlap with existing boxes (both existing annotations and new boxes)\n",
    "            all_existing = existing_boxes + new_boxes\n",
    "            overlap = False\n",
    "            \n",
    "            for ex_x, ex_y, ex_w, ex_h in all_existing:\n",
    "                # calc minimum distance needed to avoid overlap (with padding)\n",
    "                min_dist_x = (w_norm + ex_w) / 2 + 0.05  # 5% padding\n",
    "                min_dist_y = (h_norm + ex_h) / 2 + 0.05\n",
    "                \n",
    "                actual_dist_x = abs(x_center - ex_x)\n",
    "                actual_dist_y = abs(y_center - ex_y)\n",
    "                \n",
    "                if actual_dist_x < min_dist_x and actual_dist_y < min_dist_y:\n",
    "                    overlap = True\n",
    "                    break\n",
    "            \n",
    "            if not overlap:\n",
    "                new_boxes.append((x_center, y_center, w_norm, h_norm))\n",
    "                break\n",
    "        else:\n",
    "            # try a smaller box\n",
    "            if min_size > 0.08:\n",
    "                w_norm = random.uniform(0.08, min_size)\n",
    "                h_norm = random.uniform(0.08, min_size)\n",
    "                x_center = random.uniform(w_norm/2, 1 - w_norm/2)\n",
    "                y_center = random.uniform(h_norm/2, 1 - h_norm/2)\n",
    "                new_boxes.append((x_center, y_center, w_norm, h_norm))\n",
    "    \n",
    "    return new_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5deaac6d-e942-41cc-a449-21e109af930b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_unknown_training_data(image_folder, df, output_labels, class_to_id, max_unknown_samples=20):\n",
    "    \n",
    "    if \"Unknown\" not in class_to_id:\n",
    "        print(\"Unknown class not found in class mapping\")\n",
    "        return\n",
    "    \n",
    "    unknown_id = class_to_id[\"Unknown\"]\n",
    "    annotated_images = set(df['filename'].unique())\n",
    "    \n",
    "    print(f\"Using {len(annotated_images)} annotated images to generate Unknown regions\")\n",
    "    \n",
    "    unknown_count = 0\n",
    "    annotated_sample = list(annotated_images)\n",
    "    random.shuffle(annotated_sample)  # randomize selection\n",
    "    \n",
    "    for img_name in annotated_sample:\n",
    "        if unknown_count >= max_unknown_samples:\n",
    "            break\n",
    "            \n",
    "        try:\n",
    "            img_path = image_folder / img_name\n",
    "            img = Image.open(img_path)\n",
    "            img_w, img_h = img.size\n",
    "            \n",
    "            label_path = output_labels / (img_path.stem + \".txt\")\n",
    "            \n",
    "            # read existing annotations\n",
    "            existing_boxes = []\n",
    "            if label_path.exists():\n",
    "                with open(label_path, \"r\") as f:\n",
    "                    for line in f:\n",
    "                        parts = line.strip().split()\n",
    "                        if len(parts) == 5:\n",
    "                            _, x_c, y_c, w, h = map(float, parts)\n",
    "                            existing_boxes.append((x_c, y_c, w, h))\n",
    "            \n",
    "            # try to add non-overlapping unknown box\n",
    "            for attempt in range(5):\n",
    "                x_center = random.uniform(0.1, 0.9)\n",
    "                y_center = random.uniform(0.1, 0.9)\n",
    "                w_norm = random.uniform(0.1, 0.25)\n",
    "                h_norm = random.uniform(0.1, 0.25)\n",
    "                \n",
    "                # check for overlap\n",
    "                overlap = False\n",
    "                for ex_x, ex_y, ex_w, ex_h in existing_boxes:\n",
    "                    if (abs(x_center - ex_x) < (w_norm + ex_w)/2 + 0.1 and \n",
    "                        abs(y_center - ex_y) < (h_norm + ex_h)/2 + 0.1):\n",
    "                        overlap = True\n",
    "                        break\n",
    "                \n",
    "                if not overlap:\n",
    "                    with open(label_path, \"a\") as f:\n",
    "                        f.write(f\"{unknown_id} {x_center:.6f} {y_center:.6f} {w_norm:.6f} {h_norm:.6f}\\n\")\n",
    "                    \n",
    "                    unknown_count += 1\n",
    "                    print(f\"added Unknown region to annotated image: {img_name}\")\n",
    "                    break\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"error augmenting {img_name} with Unknown class: {e}\")\n",
    "    \n",
    "    print(f\"created {unknown_count} Unknown class training examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "20c144b5-03fc-440e-87e9-d7673086c4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_default_unknown_box():\n",
    "    x_center = random.uniform(0.2, 0.4)\n",
    "    y_center = random.uniform(0.2, 0.4)\n",
    "    w_norm = random.uniform(0.15, 0.25)\n",
    "    h_norm = random.uniform(0.15, 0.25)\n",
    "    \n",
    "    return x_center, y_center, w_norm, h_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "04f0c911-9938-434a-b193-483d466dec31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_overlapping_annotations_in_existing_labels(labels_dir, min_distance=0.05):\n",
    "    fixed_count = 0\n",
    "    \n",
    "    for label_file in labels_dir.glob(\"*.txt\"):\n",
    "        try:\n",
    "            # all annotations\n",
    "            annotations = []\n",
    "            with open(label_file, \"r\") as f:\n",
    "                for line in f:\n",
    "                    parts = line.strip().split()\n",
    "                    if len(parts) == 5:\n",
    "                        class_id, x_c, y_c, w, h = map(float, parts)\n",
    "                        annotations.append([int(class_id), x_c, y_c, w, h])\n",
    "            \n",
    "            if len(annotations) <= 1:\n",
    "                continue\n",
    "                \n",
    "            # check overlaps and fix them\n",
    "            modified = False\n",
    "            \n",
    "            for i in range(len(annotations)):\n",
    "                for j in range(i + 1, len(annotations)):\n",
    "                    ann1 = annotations[i]\n",
    "                    ann2 = annotations[j]\n",
    "                    \n",
    "                    # calc distance between centers\n",
    "                    dist_x = abs(ann1[1] - ann2[1])\n",
    "                    dist_y = abs(ann1[2] - ann2[2])\n",
    "                    \n",
    "                    # min distance needed\n",
    "                    min_dist_x = (ann1[3] + ann2[3]) / 2 + min_distance\n",
    "                    min_dist_y = (ann1[4] + ann2[4]) / 2 + min_distance\n",
    "                    \n",
    "                    # if overlapping -> move the second annotation\n",
    "                    if dist_x < min_dist_x and dist_y < min_dist_y:\n",
    "                        # calc new position for ann2\n",
    "                        if ann2[1] < ann1[1]:  # ann2 is to the left\n",
    "                            new_x = ann1[1] - min_dist_x\n",
    "                        else:  # ann2 is to the right\n",
    "                            new_x = ann1[1] + min_dist_x\n",
    "                            \n",
    "                        if ann2[2] < ann1[2]:  # ann2 is above\n",
    "                            new_y = ann1[2] - min_dist_y\n",
    "                        else:  # ann2 is below\n",
    "                            new_y = ann1[2] + min_dist_y\n",
    "                        \n",
    "                        # new position is within bounds\n",
    "                        half_w = ann2[3] / 2\n",
    "                        half_h = ann2[4] / 2\n",
    "                        \n",
    "                        new_x = max(half_w, min(1 - half_w, new_x))\n",
    "                        new_y = max(half_h, min(1 - half_h, new_y))\n",
    "                        \n",
    "                        annotations[j][1] = new_x\n",
    "                        annotations[j][2] = new_y\n",
    "                        modified = True\n",
    "                        \n",
    "                        print(f\"fixed overlap in {label_file.name}\")\n",
    "            \n",
    "            if modified:\n",
    "                with open(label_file, \"w\") as f:\n",
    "                    for ann in annotations:\n",
    "                        class_id, x_c, y_c, w, h = ann\n",
    "                        f.write(f\"{class_id} {x_c:.6f} {y_c:.6f} {w:.6f} {h:.6f}\\n\")\n",
    "                fixed_count += 1\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"error processing {label_file.name}: {e}\")\n",
    "    \n",
    "    print(f\"fixed overlapping annotations in {fixed_count} label files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2958d84f-8f9e-407f-be10-3a9b1aadff81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_csv_to_yolo(csv_folder=project_root / \"Annotation_CSV_Files\", \n",
    "                       image_folder=project_root / \"Images\", \n",
    "                       output_labels=project_root / \"labels\"):\n",
    "    \n",
    "    print(\"converting CSV annotations to YOLO format\")\n",
    "    \n",
    "    output_labels.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    if not csv_folder.exists():\n",
    "        print(f\"CSV folder not found: {csv_folder}\")\n",
    "        return False\n",
    "    \n",
    "    csv_files = list(csv_folder.glob(\"*.csv\"))\n",
    "    if not csv_files:\n",
    "        print(\"no CSV files found\")\n",
    "        return False\n",
    "    \n",
    "    print(f\"found {len(csv_files)} CSV files\")\n",
    "    \n",
    "    df_list = []\n",
    "    for csv_file in csv_files:\n",
    "        try:\n",
    "            df = pd.read_csv(csv_file)\n",
    "            if df.empty or df.columns.size == 0:\n",
    "                print(f\"skipping empty file: {csv_file.name}\")\n",
    "                continue\n",
    "            df_list.append(df)\n",
    "            print(f\"loaded {csv_file.name}\")\n",
    "        except pd.errors.EmptyDataError:\n",
    "            print(f\"skipping empty file: {csv_file.name}\")\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            print(f\"error loading {csv_file.name}: {e}\")\n",
    "    \n",
    "    if not df_list:\n",
    "        print(\"no valid CSV files loaded\")\n",
    "        return False\n",
    "        \n",
    "    df = pd.concat(df_list, ignore_index=True)\n",
    "    print(f\"total annotations: {len(df)}\")\n",
    "    \n",
    "    try:\n",
    "        # class extraction with normalization\n",
    "        def extract_and_normalize_class(region_attr):\n",
    "            try:\n",
    "                parsed = json.loads(region_attr)\n",
    "                raw_class = parsed.get('candy_type', 'Unknown')\n",
    "                return normalize_class_name(raw_class)\n",
    "            except:\n",
    "                return 'Unknown'\n",
    "        \n",
    "        df['class'] = df['region_attributes'].apply(extract_and_normalize_class)\n",
    "        \n",
    "        # remove any empty or invalid classes\n",
    "        df = df[df['class'].notna() & (df['class'] != '')]\n",
    "        \n",
    "        # get normalized classes and ensure consistency\n",
    "        actual_classes = sorted(df['class'].unique())\n",
    "        print(f\"normalized classes found: {actual_classes}\")\n",
    "        \n",
    "        # define the final class list based on your actual CSV data\n",
    "        predefined_classes = [\n",
    "            'Crunch', 'Baby_Ruth', 'Butterfinger', '3_Musketeers', 'Milky_Way'\n",
    "        ]\n",
    "        \n",
    "        # add any additional classes that might appear\n",
    "        additional_common_classes = [\n",
    "            'Snickers', 'Twix', '100_Grand', 'Midnight_Milky_Way'\n",
    "        ]\n",
    "        \n",
    "        # use predefined classes if they exist in data, otherwise use discovered classes\n",
    "        class_names = []\n",
    "        for cls in predefined_classes:\n",
    "            if cls in actual_classes:\n",
    "                class_names.append(cls)\n",
    "        \n",
    "        # add any additional common classes found in data\n",
    "        for cls in additional_common_classes:\n",
    "            if cls in actual_classes and cls not in class_names:\n",
    "                class_names.append(cls)\n",
    "        \n",
    "        # add any other classes found in data that are not predefined\n",
    "        for cls in actual_classes:\n",
    "            if cls not in class_names and cls != 'Unknown':\n",
    "                class_names.append(cls)\n",
    "        \n",
    "        # Unknown as the last class\n",
    "        class_names.append('Unknown')\n",
    "        \n",
    "        class_to_id = {name: i for i, name in enumerate(class_names)}\n",
    "        \n",
    "        print(f\"final {len(class_names)} classes: {class_names}\")\n",
    "        print(f\"class mapping: {class_to_id}\")\n",
    "        \n",
    "        with open(project_root / \"classes.txt\", \"w\") as f:\n",
    "            for name in class_names:\n",
    "                f.write(name + \"\\n\")\n",
    "        \n",
    "        print(\"created classes.txt\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"error extracting classes: {e}\")\n",
    "        return False\n",
    "\n",
    "    converted_count = 0\n",
    "    skipped_count = 0\n",
    "    unknown_dimension_count = 0\n",
    "    class_distribution = Counter()\n",
    "    \n",
    "    for filename in df['filename'].unique():\n",
    "        img_path = image_folder / filename\n",
    "        label_path = output_labels / (img_path.stem + \".txt\")\n",
    "        \n",
    "        if not img_path.exists():\n",
    "            print(f\"image not found: {img_path}\")\n",
    "            skipped_count += 1\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            img = Image.open(img_path)\n",
    "            img_w, img_h = img.size\n",
    "        except Exception as e:\n",
    "            print(f\"failed to open image {filename}: {e}\")\n",
    "            skipped_count += 1\n",
    "            continue\n",
    "\n",
    "        with open(label_path, \"w\") as f:\n",
    "            rows = df[df['filename'] == filename]\n",
    "            valid_annotations = 0\n",
    "            \n",
    "            for _, row in rows.iterrows():\n",
    "                try:\n",
    "                    # parse the region shape attributes\n",
    "                    shape_str = row['region_shape_attributes']\n",
    "                    \n",
    "                    # check if dimensions are missing or invalid\n",
    "                    if pd.isna(shape_str) or shape_str == '{}' or shape_str.strip() == '':\n",
    "                        print(f\"no dimensions found for annotation in {filename}, marking as Unknown\")\n",
    "                        \n",
    "                        # create a default bounding box for Unknown class (center of image)\n",
    "                        x_center, y_center, w_norm, h_norm = create_default_unknown_box()\n",
    "                        \n",
    "                        unknown_id = class_to_id['Unknown']\n",
    "                        f.write(f\"{unknown_id} {x_center:.6f} {y_center:.6f} {w_norm:.6f} {h_norm:.6f}\\n\")\n",
    "                        \n",
    "                        class_distribution['Unknown'] += 1\n",
    "                        unknown_dimension_count += 1\n",
    "                        valid_annotations += 1\n",
    "                        continue\n",
    "                    \n",
    "                    shape = json.loads(shape_str)\n",
    "                    label = row['class']\n",
    "                    \n",
    "                    if label not in class_to_id:\n",
    "                        print(f\"skipping unknown class '{label}' in {filename}\")\n",
    "                        continue\n",
    "                    \n",
    "                    # check if required dimension fields are present and valid\n",
    "                    required_fields = ['x', 'y', 'width', 'height']\n",
    "                    missing_fields = [field for field in required_fields if field not in shape or shape[field] is None]\n",
    "                    \n",
    "                    if missing_fields:\n",
    "                        print(f\"missing dimension fields {missing_fields} in {filename}, marking as Unknown\")\n",
    "                        \n",
    "                        # create a default bounding box for Unknown class\n",
    "                        x_center, y_center, w_norm, h_norm = create_default_unknown_box()\n",
    "                        \n",
    "                        unknown_id = class_to_id['Unknown']\n",
    "                        f.write(f\"{unknown_id} {x_center:.6f} {y_center:.6f} {w_norm:.6f} {h_norm:.6f}\\n\")\n",
    "                        \n",
    "                        class_distribution['Unknown'] += 1\n",
    "                        unknown_dimension_count += 1\n",
    "                        valid_annotations += 1\n",
    "                        continue\n",
    "                    \n",
    "                    class_id = class_to_id[label]\n",
    "                    class_distribution[label] += 1\n",
    "\n",
    "                    # extract dimensions\n",
    "                    x, y, w, h = shape['x'], shape['y'], shape['width'], shape['height']\n",
    "                    \n",
    "                    # check for invalid dimensions (zero, negative, or unreasonable values)\n",
    "                    if w <= 0 or h <= 0 or x < 0 or y < 0:\n",
    "                        print(f\"invalid dimensions in {filename}: x={x}, y={y}, w={w}, h={h}, marking as Unknown\")\n",
    "                        \n",
    "                        # create a default bounding box for Unknown class\n",
    "                        x_center, y_center, w_norm, h_norm = create_default_unknown_box()\n",
    "                        \n",
    "                        unknown_id = class_to_id['Unknown']\n",
    "                        f.write(f\"{unknown_id} {x_center:.6f} {y_center:.6f} {w_norm:.6f} {h_norm:.6f}\\n\")\n",
    "                        \n",
    "                        class_distribution['Unknown'] += 1\n",
    "                        unknown_dimension_count += 1\n",
    "                        valid_annotations += 1\n",
    "                        continue\n",
    "                    \n",
    "                    # validate bounding box is within image bounds with tolerance\n",
    "                    if x < -5 or y < -5 or x + w > img_w + 5 or y + h > img_h + 5:\n",
    "                        print(f\"bounding box outside image bounds in {filename}: ({x},{y},{w},{h}) for image {img_w}x{img_h}, marking as Unknown\")\n",
    "                        \n",
    "                        # instead of clipping, mark as Unknown\n",
    "                        x_center, y_center, w_norm, h_norm = create_default_unknown_box()\n",
    "                        \n",
    "                        unknown_id = class_to_id['Unknown']\n",
    "                        f.write(f\"{unknown_id} {x_center:.6f} {y_center:.6f} {w_norm:.6f} {h_norm:.6f}\\n\")\n",
    "                        \n",
    "                        class_distribution['Unknown'] += 1\n",
    "                        unknown_dimension_count += 1\n",
    "                        valid_annotations += 1\n",
    "                        continue\n",
    "                    \n",
    "                    if w <= 5 or h <= 5:\n",
    "                        print(f\"box too small in {filename}: width={w}, height={h}, marking as Unknown\")\n",
    "                        \n",
    "                        # instead of skipping, mark as Unknown\n",
    "                        x_center, y_center, w_norm, h_norm = create_default_unknown_box()\n",
    "                        \n",
    "                        unknown_id = class_to_id['Unknown']\n",
    "                        f.write(f\"{unknown_id} {x_center:.6f} {y_center:.6f} {w_norm:.6f} {h_norm:.6f}\\n\")\n",
    "                        \n",
    "                        class_distribution['Unknown'] += 1\n",
    "                        unknown_dimension_count += 1\n",
    "                        valid_annotations += 1\n",
    "                        continue\n",
    "                    \n",
    "                    # convert to YOLO format with precision\n",
    "                    x_center = (x + w / 2) / img_w\n",
    "                    y_center = (y + h / 2) / img_h\n",
    "                    w_norm = w / img_w\n",
    "                    h_norm = h / img_h\n",
    "                    \n",
    "                    # bounds checking\n",
    "                    if not (0 <= x_center <= 1 and 0 <= y_center <= 1 and 0 < w_norm <= 1 and 0 < h_norm <= 1):\n",
    "                        print(f\"normalized coordinates out of bounds in {filename}: {x_center}, {y_center}, {w_norm}, {h_norm}, marking as Unknown\")\n",
    "                        \n",
    "                        # instead of skipping, mark as Unknown\n",
    "                        x_center, y_center, w_norm, h_norm = create_default_unknown_box()\n",
    "                        \n",
    "                        unknown_id = class_to_id['Unknown']\n",
    "                        f.write(f\"{unknown_id} {x_center:.6f} {y_center:.6f} {w_norm:.6f} {h_norm:.6f}\\n\")\n",
    "                        \n",
    "                        class_distribution['Unknown'] += 1\n",
    "                        unknown_dimension_count += 1\n",
    "                        valid_annotations += 1\n",
    "                        continue\n",
    "                    \n",
    "                    # valid annotation -> write it\n",
    "                    f.write(f\"{class_id} {x_center:.6f} {y_center:.6f} {w_norm:.6f} {h_norm:.6f}\\n\")\n",
    "                    valid_annotations += 1\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"error processing annotation in {filename}: {e}, marking as Unknown\")\n",
    "                    \n",
    "                    # when there is any error, create Unknown annotation\n",
    "                    x_center, y_center, w_norm, h_norm = create_default_unknown_box()\n",
    "                    \n",
    "                    unknown_id = class_to_id['Unknown']\n",
    "                    f.write(f\"{unknown_id} {x_center:.6f} {y_center:.6f} {w_norm:.6f} {h_norm:.6f}\\n\")\n",
    "                    \n",
    "                    class_distribution['Unknown'] += 1\n",
    "                    unknown_dimension_count += 1\n",
    "                    valid_annotations += 1\n",
    "                    continue\n",
    "            \n",
    "            if valid_annotations > 0:\n",
    "                converted_count += 1\n",
    "            else:\n",
    "                # remove empty label file\n",
    "                if label_path.exists():\n",
    "                    label_path.unlink()\n",
    "    \n",
    "    print(f\"converted {converted_count} image-label pairs, skipped {skipped_count}\")\n",
    "    print(f\"created {unknown_dimension_count} Unknown class annotations from missing/invalid dimensions\")\n",
    "    print(f\"class distribution: {dict(class_distribution)}\")\n",
    "    return converted_count > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "646626f9-26c5-4940-867b-3092369a637c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to check for missing dimensions in CSV\n",
    "def analyze_csv_for_dimension_issues(csv_folder=project_root / \"Annotation_CSV_Files\"):\n",
    "    \n",
    "    if not csv_folder.exists():\n",
    "        print(f\"CSV folder not found: {csv_folder}\")\n",
    "        return False\n",
    "    \n",
    "    csv_files = list(csv_folder.glob(\"*.csv\"))\n",
    "    if not csv_files:\n",
    "        print(\"no CSV files found\")\n",
    "        return False\n",
    "    \n",
    "    total_annotations = 0\n",
    "    missing_dimensions = 0\n",
    "    invalid_dimensions = 0\n",
    "    empty_shape_attrs = 0\n",
    "    valid_dimensions = 0\n",
    "    \n",
    "    for csv_file in csv_files:\n",
    "        try:\n",
    "            df = pd.read_csv(csv_file)\n",
    "            if df.empty:\n",
    "                continue\n",
    "                \n",
    "            print(f\"\\nanalyzing {csv_file.name}:\")\n",
    "            \n",
    "            for _, row in df.iterrows():\n",
    "                total_annotations += 1\n",
    "                \n",
    "                # check region_shape_attributes\n",
    "                shape_str = row.get('region_shape_attributes', '')\n",
    "                \n",
    "                if pd.isna(shape_str) or shape_str == '{}' or shape_str.strip() == '':\n",
    "                    empty_shape_attrs += 1\n",
    "                    print(f\"  empty shape attributes in row {total_annotations}\")\n",
    "                    continue\n",
    "                \n",
    "                try:\n",
    "                    shape = json.loads(shape_str)\n",
    "                    \n",
    "                    # check for required fields\n",
    "                    required_fields = ['x', 'y', 'width', 'height']\n",
    "                    missing_fields = [field for field in required_fields if field not in shape]\n",
    "                    \n",
    "                    if missing_fields:\n",
    "                        missing_dimensions += 1\n",
    "                        print(f\"  missing fields {missing_fields} in row {total_annotations}\")\n",
    "                        continue\n",
    "                    \n",
    "                    # check for invalid values\n",
    "                    x, y, w, h = shape['x'], shape['y'], shape['width'], shape['height']\n",
    "                    \n",
    "                    if any(val is None for val in [x, y, w, h]):\n",
    "                        invalid_dimensions += 1\n",
    "                        print(f\"  null dimension values in row {total_annotations}\")\n",
    "                        continue\n",
    "\n",
    "                    if w <= 0 or h <= 0:\n",
    "                        invalid_dimensions += 1\n",
    "                        print(f\"  invalid dimensions (w={w}, h={h}) in row {total_annotations}\")\n",
    "                        continue\n",
    "                    \n",
    "                    valid_dimensions += 1\n",
    "                    \n",
    "                except json.JSONDecodeError:\n",
    "                    missing_dimensions += 1\n",
    "                    print(f\"  invalid JSON in shape attributes, row {total_annotations}\")\n",
    "                except Exception as e:\n",
    "                    invalid_dimensions += 1\n",
    "                    print(f\"  error parsing dimensions in row {total_annotations}: {e}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"error reading {csv_file.name}: {e}\")\n",
    "    \n",
    "    print(f\"total annotations: {total_annotations}\")\n",
    "    print(f\"valid dimensions: {valid_dimensions}\")\n",
    "    print(f\"empty shape attributes: {empty_shape_attrs}\")\n",
    "    print(f\"missing dimension fields: {missing_dimensions}\")\n",
    "    print(f\"invalid dimension values: {invalid_dimensions}\")\n",
    "    \n",
    "    issues_found = empty_shape_attrs + missing_dimensions + invalid_dimensions\n",
    "    print(f\"total issues that will be marked as Unknown: {issues_found}\")\n",
    "    \n",
    "    if issues_found > 0:\n",
    "        percentage = (issues_found / total_annotations) * 100\n",
    "        print(f\"percentage of annotations that will become Unknown: {percentage:.1f}%\")\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "29d46b27-bb19-4831-bde4-72f464e42475",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_val_split(train_ratio=0.8, root_dir=project_root):\n",
    "    \n",
    "    print(\"creating train/validation split with class balancing\")\n",
    "    \n",
    "    images_dir = root_dir / \"Images\"\n",
    "    labels_dir = root_dir / \"labels\"\n",
    "    train_img_dir = root_dir / \"dataset/images/train\"\n",
    "    val_img_dir = root_dir / \"dataset/images/val\"\n",
    "    train_label_dir = root_dir / \"dataset/labels/train\"\n",
    "    val_label_dir = root_dir / \"dataset/labels/val\"\n",
    "    \n",
    "    if not images_dir.exists() or not labels_dir.exists():\n",
    "        print(\"images or labels directory not found\")\n",
    "        return False\n",
    "\n",
    "    # file matching logic\n",
    "    image_files = {}\n",
    "    for img_file in images_dir.glob(\"*\"):\n",
    "        if img_file.suffix.lower() in [\".jpg\", \".jpeg\", \".png\"]:\n",
    "            stem = img_file.stem\n",
    "            image_files[stem] = img_file.name\n",
    "\n",
    "    label_files = {}\n",
    "    for label_file in labels_dir.glob(\"*.txt\"):\n",
    "        stem = label_file.stem\n",
    "        label_files[stem] = label_file.name\n",
    "\n",
    "    print(f\"found {len(image_files)} images and {len(label_files)} labels\")\n",
    "\n",
    "    # match pairs and analyze class distribution\n",
    "    matched_pairs = []\n",
    "    class_to_files = {}\n",
    "    \n",
    "    for stem in image_files.keys():\n",
    "        if stem in label_files:\n",
    "            # read label file to get classes\n",
    "            label_path = labels_dir / label_files[stem]\n",
    "            classes_in_image = set()\n",
    "            \n",
    "            try:\n",
    "                with open(label_path, 'r') as f:\n",
    "                    for line in f:\n",
    "                        parts = line.strip().split()\n",
    "                        if len(parts) >= 1:\n",
    "                            class_id = int(parts[0])\n",
    "                            classes_in_image.add(class_id)\n",
    "                \n",
    "                matched_pairs.append((image_files[stem], label_files[stem], classes_in_image))\n",
    "                \n",
    "                # track which files contain each class\n",
    "                for class_id in classes_in_image:\n",
    "                    if class_id not in class_to_files:\n",
    "                        class_to_files[class_id] = []\n",
    "                    class_to_files[class_id].append(len(matched_pairs) - 1)\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error reading {label_path}: {e}\")\n",
    "                matched_pairs.append((image_files[stem], label_files[stem], set()))\n",
    "\n",
    "    print(f\"found {len(matched_pairs)} matching image-label pairs\")\n",
    "    print(f\"class distribution in files: {[(k, len(v)) for k, v in class_to_files.items()]}\")\n",
    "\n",
    "    if len(matched_pairs) == 0:\n",
    "        print(\"no matching pairs found\")\n",
    "        return False\n",
    "\n",
    "    random.seed(42)\n",
    "    train_indices = set()\n",
    "    val_indices = set()\n",
    "    \n",
    "    for class_id, file_indices in class_to_files.items():\n",
    "        random.shuffle(file_indices)\n",
    "        split_point = int(len(file_indices) * train_ratio)\n",
    "        \n",
    "        for i in file_indices[:split_point]:\n",
    "            train_indices.add(i)\n",
    "        for i in file_indices[split_point:]:\n",
    "            val_indices.add(i)\n",
    "    \n",
    "    # check files in both sets\n",
    "    all_indices = set(range(len(matched_pairs)))\n",
    "    remaining_indices = all_indices - train_indices - val_indices\n",
    "    \n",
    "    # distribute remaining files\n",
    "    remaining_list = list(remaining_indices)\n",
    "    random.shuffle(remaining_list)\n",
    "    split_point = int(len(remaining_list) * train_ratio)\n",
    "    \n",
    "    train_indices.update(remaining_list[:split_point])\n",
    "    val_indices.update(remaining_list[split_point:])\n",
    "\n",
    "    train_pairs = [matched_pairs[i] for i in train_indices]\n",
    "    val_pairs = [matched_pairs[i] for i in val_indices]\n",
    "\n",
    "    print(f\"stratified split: {len(train_pairs)} training, {len(val_pairs)} validation\")\n",
    "\n",
    "    # clear existing files first\n",
    "    for dir_path in [train_img_dir, val_img_dir, train_label_dir, val_label_dir]:\n",
    "        if dir_path.exists():\n",
    "            for file in dir_path.glob(\"*\"):\n",
    "                file.unlink()\n",
    "\n",
    "    train_success = 0\n",
    "    val_success = 0\n",
    "\n",
    "    for img_file, label_file, _ in train_pairs:\n",
    "        try:\n",
    "            shutil.copy2(images_dir / img_file, train_img_dir / img_file)\n",
    "            shutil.copy2(labels_dir / label_file, train_label_dir / label_file)\n",
    "            train_success += 1\n",
    "        except Exception as e:\n",
    "            print(f\"failed to copy training pair {img_file}: {e}\")\n",
    "\n",
    "    for img_file, label_file, _ in val_pairs:\n",
    "        try:\n",
    "            shutil.copy2(images_dir / img_file, val_img_dir / img_file)\n",
    "            shutil.copy2(labels_dir / label_file, val_label_dir / label_file)\n",
    "            val_success += 1\n",
    "        except Exception as e:\n",
    "            print(f\"failed to copy validation pair {img_file}: {e}\")\n",
    "\n",
    "    print(f\"successfully created {train_success} training and {val_success} validation pairs\")\n",
    "    return train_success > 0 and val_success > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f61b64d7-77d6-4405-9e24-ffec8781bf26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_yaml(root_dir):    \n",
    "    print(\"creating data.yaml\")\n",
    "    \n",
    "    classes_file = root_dir / \"classes.txt\"\n",
    "    \n",
    "    try:\n",
    "        with open(classes_file, \"r\") as f:\n",
    "            class_names = [line.strip() for line in f.readlines() if line.strip()]\n",
    "    except FileNotFoundError:\n",
    "        print(f\"{classes_file} not found!\")\n",
    "        return False\n",
    "\n",
    "    data_content = {\n",
    "        'path': str(root_dir / 'dataset'),\n",
    "        'train': 'images/train',\n",
    "        'val': 'images/val',\n",
    "        'nc': len(class_names),\n",
    "        'names': class_names\n",
    "    }\n",
    "\n",
    "    output_yaml = root_dir / 'data.yaml'\n",
    "    with open(output_yaml, 'w') as f:\n",
    "        yaml.dump(data_content, f, default_flow_style=False, sort_keys=False)\n",
    "\n",
    "    print(f\"created data.yaml with {len(class_names)} classes\")\n",
    "    print(f\"classes: {class_names}\")\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c4e9a30d-7197-4cb6-9cc1-f207f111452c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(epochs=100, img_size=640, batch_size=16, root_dir=project_root):    \n",
    "    print(\"starting model training\")\n",
    "    \n",
    "    data_yaml = root_dir / \"data.yaml\"\n",
    "    \n",
    "    if not data_yaml.exists():\n",
    "        print(f\"{data_yaml} not found\")\n",
    "        return False\n",
    "\n",
    "    try:\n",
    "        # YOLOv8s for better accuracy than nano\n",
    "        model = YOLO('yolov8s.pt')\n",
    "\n",
    "        # training parameters\n",
    "        results = model.train(\n",
    "            data=str(data_yaml),\n",
    "            epochs=epochs,\n",
    "            imgsz=img_size,\n",
    "            batch=batch_size,\n",
    "            name='candy_detection',\n",
    "            patience=40,\n",
    "            save=True,\n",
    "            plots=True,\n",
    "            verbose=True,\n",
    "            # learning rate schedule\n",
    "            lr0=0.01,\n",
    "            lrf=0.01,\n",
    "            # regularization\n",
    "            weight_decay=0.0005,\n",
    "            momentum=0.937,\n",
    "            # data augmentation for better generalization\n",
    "            hsv_h=0.015,\n",
    "            hsv_s=0.7,\n",
    "            hsv_v=0.4,\n",
    "            degrees=10.0,\n",
    "            translate=0.1,\n",
    "            scale=0.5,\n",
    "            shear=0.0,\n",
    "            perspective=0.0,\n",
    "            flipud=0.0,\n",
    "            fliplr=0.5,\n",
    "            mosaic=1.0,\n",
    "            mixup=0.1,\n",
    "            copy_paste=0.1,\n",
    "            # class balancing\n",
    "            cls=0.5,\n",
    "            box=0.05,\n",
    "            # confidence thresholds\n",
    "            conf=0.001,  # lower for training to catch more examples\n",
    "            iou=0.6,\n",
    "        )\n",
    "\n",
    "        print(\"training completed\")\n",
    "        print(f\"results saved in: runs/detect/candy_detection/\")\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"training failed: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1df3ee6f-e90d-41fb-9424-35fac6b816a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for existing trained model\n",
    "def find_best_model(runs_dir=\"runs/detect\"):\n",
    "    runs_path = Path(runs_dir)\n",
    "    if not runs_path.exists():\n",
    "        print(f\"no runs directory found at {runs_path}\")\n",
    "        return None\n",
    "\n",
    "    run_dirs = sorted(\n",
    "        [d for d in runs_path.iterdir() if (d / \"weights\" / \"best.pt\").exists()],\n",
    "        key=lambda d: d.stat().st_mtime,\n",
    "        reverse=True\n",
    "    )\n",
    "\n",
    "    if not run_dirs:\n",
    "        print(\"no trained model found\")\n",
    "        return None\n",
    "\n",
    "    best_model_path = run_dirs[0] / \"weights\" / \"best.pt\"\n",
    "    print(f\"Found model: {best_model_path}\")\n",
    "    return str(best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9c7375d8-cc78-4bcc-9e33-2d45f1a289f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_single_image(image_path, model_path=None, conf_threshold=0.25, unknown_threshold=0.5):\n",
    "    \n",
    "    print(f\"testing detection on: {image_path}\")\n",
    "    \n",
    "    if model_path is None:\n",
    "        model_path = find_best_model()\n",
    "        if model_path is None:\n",
    "            return False\n",
    "    \n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"image not found: {image_path}\")\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        model = YOLO(model_path)\n",
    "        print(f\"model loaded: {model_path}\")\n",
    "        \n",
    "        # class names\n",
    "        class_names = model.names\n",
    "        print(f\"model classes: {class_names}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"error loading model: {e}\")\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            print(\"could not load image\")\n",
    "            return False\n",
    "        \n",
    "        height, width = image.shape[:2]\n",
    "        print(f\"image size: {width}x{height}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"error loading image: {e}\")\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        # run detection with multiple confidence levels for comparison\n",
    "        results_low = model(image, conf=0.1)  # very low for comprehensive detection\n",
    "        results_medium = model(image, conf=conf_threshold)\n",
    "        results_high = model(image, conf=unknown_threshold)\n",
    "        \n",
    "        # process results with confidence-based classification\n",
    "        final_detections = []\n",
    "        result_image = image.copy()\n",
    "        \n",
    "        # use medium confidence results as base\n",
    "        for result in results_medium:\n",
    "            if hasattr(result, 'boxes') and result.boxes is not None:\n",
    "                for box in result.boxes:\n",
    "                    if box.xyxy is None or box.conf is None or box.cls is None:\n",
    "                        continue\n",
    "                    \n",
    "                    x1, y1, x2, y2 = map(int, box.xyxy[0].cpu().numpy())\n",
    "                    conf = float(box.conf[0].cpu().numpy())\n",
    "                    class_id = int(box.cls[0].cpu().numpy())\n",
    "                    class_name = class_names.get(class_id, f\"Class_{class_id}\")\n",
    "                    \n",
    "                    # unknown detection logic\n",
    "                    display_name = class_name\n",
    "                    is_uncertain = False\n",
    "                    color = (0, 255, 0)  # default green\n",
    "                    \n",
    "                    if class_name == \"Unknown\":\n",
    "                        display_name = \"Unknown\"\n",
    "                        color = (0, 0, 255)  # red for unknown\n",
    "                    elif conf < unknown_threshold and class_name != \"Unknown\":\n",
    "                        display_name = f\"Uncertain_{class_name}\"\n",
    "                        is_uncertain = True\n",
    "                        color = (0, 165, 255)  # orange for uncertain\n",
    "                    else:\n",
    "                        # high confidence known class\n",
    "                        colors = [(0, 255, 0), (255, 0, 0), (0, 255, 255), (255, 255, 0), \n",
    "                                 (255, 0, 255), (128, 0, 128), (255, 165, 0), (0, 128, 255)]\n",
    "                        color = colors[class_id % len(colors)]\n",
    "                    \n",
    "                    final_detections.append({\n",
    "                        'class': display_name,\n",
    "                        'original_class': class_name,\n",
    "                        'confidence': conf,\n",
    "                        'box': [x1, y1, x2, y2],\n",
    "                        'uncertain': is_uncertain,\n",
    "                        'class_id': class_id\n",
    "                    })\n",
    "                    \n",
    "                    # draw bounding box\n",
    "                    cv2.rectangle(result_image, (x1, y1), (x2, y2), color, 3)\n",
    "                    \n",
    "                    # label with better positioning\n",
    "                    label = f\"{display_name} {conf:.2f}\"\n",
    "                    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                    font_scale = 0.6\n",
    "                    thickness = 2\n",
    "                    \n",
    "                    (text_width, text_height), baseline = cv2.getTextSize(label, font, font_scale, thickness)\n",
    "                    \n",
    "                    # position label above box, or below if near top\n",
    "                    label_y = y1 - 10 if y1 - text_height - 10 > 0 else y2 + text_height + 10\n",
    "                    \n",
    "                    # draw background rectangle for text\n",
    "                    cv2.rectangle(result_image, \n",
    "                                (x1, label_y - text_height - 5), \n",
    "                                (x1 + text_width, label_y + 5), \n",
    "                                color, -1)\n",
    "                    \n",
    "                    # draw text\n",
    "                    cv2.putText(result_image, label, (x1, label_y), \n",
    "                              font, font_scale, (255, 255, 255), thickness)\n",
    "        \n",
    "        # analysis\n",
    "        if len(final_detections) == 0:\n",
    "            print(\"no detections found:\")\n",
    "            print(\"1. try lowering confidence threshold\")\n",
    "            print(\"2. check if model was trained on similar candy types\")\n",
    "            print(\"3. image may contain only unknown/new candy types\")\n",
    "        else:\n",
    "            print(f\"\\nfound {len(final_detections)} detections:\")\n",
    "            \n",
    "            # group by class for better analysis\n",
    "            class_counts = {}\n",
    "            for det in final_detections:\n",
    "                key = det['class']\n",
    "                if key not in class_counts:\n",
    "                    class_counts[key] = []\n",
    "                class_counts[key].append(det['confidence'])\n",
    "            \n",
    "            for class_name, confidences in class_counts.items():\n",
    "                avg_conf = sum(confidences) / len(confidences)\n",
    "                print(f\"  {class_name}: {len(confidences)} instances (avg conf: {avg_conf:.3f})\")\n",
    "            \n",
    "            # detailed detection list\n",
    "            print(\"\\ndetailed detections:\")\n",
    "            for i, det in enumerate(final_detections):\n",
    "                status = \" [UNCERTAIN]\" if det.get('uncertain', False) else \"\"\n",
    "                print(f\"  {i+1}. {det['class']} ({det['confidence']:.3f}){status}\")\n",
    "\n",
    "        # result\n",
    "        os.makedirs(\"test_results\", exist_ok=True)\n",
    "        output_path = Path(\"test_results\") / f\"detection_{Path(image_path).stem}.jpg\"\n",
    "        cv2.imwrite(str(output_path), result_image)\n",
    "        print(f\"\\nresult saved to: {output_path.resolve()}\")\n",
    "        \n",
    "        return True, final_detections, result_image\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"error during detection: {e}\")\n",
    "        return False, [], None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "85511d63-e1e2-430e-ab33-d3ea86c7eb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_model_classes(model_path=None):\n",
    "    \n",
    "    if model_path is None:\n",
    "        model_path = find_best_model()\n",
    "        if model_path is None:\n",
    "            return False\n",
    "    \n",
    "    try:\n",
    "        model = YOLO(model_path)\n",
    "        class_names = model.names\n",
    "        \n",
    "        print(f\"\\nmodel classes analysis:\")\n",
    "        print(f\"total classes: {len(class_names)}\")\n",
    "        print(\"class mapping:\")\n",
    "        for class_id, class_name in class_names.items():\n",
    "            print(f\"  {class_id}: {class_name}\")\n",
    "        \n",
    "        return class_names\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"error analyzing model: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7135d21e-80e9-4049-809d-6f874fdbceae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_multiple_images(image_folder=\"Images\", model_path=None, conf_threshold=0.25):    \n",
    "    image_folder = Path(image_folder)\n",
    "    \n",
    "    print(f\"testing detection on images in: {image_folder}\")\n",
    "    \n",
    "    if model_path is None:\n",
    "        model_path = find_best_model()\n",
    "        if model_path is None:\n",
    "            return False\n",
    "    \n",
    "    try:\n",
    "        model = YOLO(model_path)\n",
    "        class_names = model.names\n",
    "        print(f\"model loaded with {len(class_names)} classes: {list(class_names.values())}\")\n",
    "    except Exception as e:\n",
    "        print(f\"error loading model: {e}\")\n",
    "        return False\n",
    "    \n",
    "    if not image_folder.exists() or not image_folder.is_dir():\n",
    "        print(f\"image folder does not exist: {image_folder}\")\n",
    "        return False\n",
    "    \n",
    "    # all image files\n",
    "    image_files = []\n",
    "    for ext in ['.jpg', '.jpeg', '.png', '.JPG', '.JPEG', '.PNG']:\n",
    "        image_files.extend(image_folder.glob(f\"*{ext}\"))\n",
    "    \n",
    "    if not image_files:\n",
    "        print(f\"no images found in {image_folder}\")\n",
    "        return False\n",
    "    \n",
    "    print(f\"found {len(image_files)} images\")\n",
    "    \n",
    "    # analysis\n",
    "    total_detections = 0\n",
    "    processed_count = 0\n",
    "    class_counts = Counter()\n",
    "    confidence_scores = []\n",
    "    images_with_detections = 0\n",
    "    \n",
    "    # test on more images for better statistics\n",
    "    test_images = image_files[:50] if len(image_files) > 50 else image_files\n",
    "    \n",
    "    for img_path in test_images:\n",
    "        try:\n",
    "            image = cv2.imread(str(img_path))\n",
    "            if image is None:\n",
    "                print(f\"could not load image {img_path}\")\n",
    "                continue\n",
    "            \n",
    "            results = model(image, conf=conf_threshold)\n",
    "            \n",
    "            image_detections = 0\n",
    "            image_classes = []\n",
    "            \n",
    "            for result in results:\n",
    "                if hasattr(result, 'boxes') and result.boxes is not None:\n",
    "                    for box in result.boxes:\n",
    "                        class_id = int(box.cls[0].cpu().numpy())\n",
    "                        class_name = class_names.get(class_id, f\"Class_{class_id}\")\n",
    "                        conf = float(box.conf[0].cpu().numpy())\n",
    "                        \n",
    "                        # Apply same uncertainty logic as single image test\n",
    "                        if class_name != \"Unknown\" and conf < 0.5:\n",
    "                            display_name = f\"Uncertain_{class_name}\"\n",
    "                        else:\n",
    "                            display_name = class_name\n",
    "                        \n",
    "                        image_classes.append(f\"{display_name}({conf:.2f})\")\n",
    "                        class_counts[display_name] += 1\n",
    "                        confidence_scores.append(conf)\n",
    "                        image_detections += 1\n",
    "            \n",
    "            total_detections += image_detections\n",
    "            processed_count += 1\n",
    "            \n",
    "            if image_detections > 0:\n",
    "                images_with_detections += 1\n",
    "                print(f\"{img_path.name}: {image_detections} detections - {', '.join(image_classes)}\")\n",
    "            else:\n",
    "                print(f\"{img_path.name}: no detections\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"error processing {img_path.name}: {e}\")\n",
    "    \n",
    "    # summary\n",
    "    print(f\"images processed: {processed_count}\")\n",
    "    print(f\"images with detections: {images_with_detections}\")\n",
    "    print(f\"total detections: {total_detections}\")\n",
    "    print(f\"average detections per image: {total_detections/processed_count:.2f}\")\n",
    "    print(f\"detection rate: {images_with_detections/processed_count*100:.1f}%\")\n",
    "    \n",
    "    if confidence_scores:\n",
    "        avg_conf = sum(confidence_scores) / len(confidence_scores)\n",
    "        print(f\"average confidence: {avg_conf:.3f}\")\n",
    "        print(f\"confidence range: {min(confidence_scores):.3f} - {max(confidence_scores):.3f}\")\n",
    "    \n",
    "    print(f\"\\nclass distribution:\")\n",
    "    for class_name, count in class_counts.most_common():\n",
    "        percentage = count / total_detections * 100 if total_detections > 0 else 0\n",
    "        print(f\"  {class_name}: {count} ({percentage:.1f}%)\")\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c8dfd7ec-c63a-4b5b-9e04-63c7ceeeccef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_training_data(root_dir=project_root):\n",
    "    \n",
    "    train_img_dir = root_dir / \"dataset/images/train\"\n",
    "    train_label_dir = root_dir / \"dataset/labels/train\"\n",
    "    val_img_dir = root_dir / \"dataset/images/val\" \n",
    "    val_label_dir = root_dir / \"dataset/labels/val\"\n",
    "    \n",
    "    # directories exist\n",
    "    for dir_path, name in [(train_img_dir, \"train images\"), (train_label_dir, \"train labels\"),\n",
    "                          (val_img_dir, \"val images\"), (val_label_dir, \"val labels\")]:\n",
    "        if not dir_path.exists():\n",
    "            print(f\"error: {name} directory not found: {dir_path}\")\n",
    "            return False\n",
    "    \n",
    "    # count files\n",
    "    train_imgs = len(list(train_img_dir.glob(\"*\")))\n",
    "    train_labels = len(list(train_label_dir.glob(\"*.txt\")))\n",
    "    val_imgs = len(list(val_img_dir.glob(\"*\")))\n",
    "    val_labels = len(list(val_label_dir.glob(\"*.txt\")))\n",
    "    \n",
    "    print(f\"training: {train_imgs} images, {train_labels} labels\")\n",
    "    print(f\"validation: {val_imgs} images, {val_labels} labels\")\n",
    "    \n",
    "    # class distribution\n",
    "    try:\n",
    "        with open(root_dir / \"classes.txt\", \"r\") as f:\n",
    "            class_names = [line.strip() for line in f.readlines()]\n",
    "        \n",
    "        class_counts = Counter()\n",
    "        total_annotations = 0\n",
    "        \n",
    "        for label_file in train_label_dir.glob(\"*.txt\"):\n",
    "            with open(label_file, \"r\") as f:\n",
    "                for line in f:\n",
    "                    parts = line.strip().split()\n",
    "                    if len(parts) >= 1:\n",
    "                        class_id = int(parts[0])\n",
    "                        if class_id < len(class_names):\n",
    "                            class_counts[class_names[class_id]] += 1\n",
    "                        total_annotations += 1\n",
    "        \n",
    "        print(f\"\\ntraining class distribution ({total_annotations} total annotations):\")\n",
    "        for class_name in class_names:\n",
    "            count = class_counts.get(class_name, 0)\n",
    "            percentage = count / total_annotations * 100 if total_annotations > 0 else 0\n",
    "            print(f\"  {class_name}: {count} ({percentage:.1f}%)\")\n",
    "        \n",
    "        # check class imbalance\n",
    "        if class_counts:\n",
    "            max_count = max(class_counts.values())\n",
    "            min_count = min(class_counts.values())\n",
    "            imbalance_ratio = max_count / min_count if min_count > 0 else float('inf')\n",
    "            \n",
    "            print(f\"\\nclass balance analysis:\")\n",
    "            print(f\"  max/min ratio: {imbalance_ratio:.2f}\")\n",
    "            \n",
    "            if imbalance_ratio > 10:\n",
    "                print(\"  significant class imbalance detected\")\n",
    "            elif imbalance_ratio > 5:\n",
    "                print(\"  moderate class imbalance detected\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"error analyzing class distribution: {e}\")\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "525a8028-fafd-46d6-8e84-d861050647d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: analyzing CSV data\n",
      "\n",
      "analyzing Candy_Project_1930-1981_csv.csv:\n",
      "  columns: ['filename', 'file_size', 'file_attributes', 'region_count', 'region_id', 'region_shape_attributes', 'region_attributes']\n",
      "  rows: 201\n",
      "  sample region_attributes:\n",
      "    1. raw: 'Crunch' -> normalized: 'Crunch'\n",
      "    2. raw: 'Butterfingers' -> normalized: 'Butterfinger'\n",
      "    3. raw: '100_Grand' -> normalized: '100_Grand'\n",
      "\n",
      "analyzing Candy_Project_2039-2092_csv.csv:\n",
      "  columns: ['filename', 'file_size', 'file_attributes', 'region_count', 'region_id', 'region_shape_attributes', 'region_attributes']\n",
      "  rows: 200\n",
      "  sample region_attributes:\n",
      "    1. raw: 'Baby_Ruth' -> normalized: 'Baby_Ruth'\n",
      "    2. raw: '3_Musketeers' -> normalized: '3_Musketeers'\n",
      "    3. raw: 'Milky_Way' -> normalized: 'Milky_Way'\n",
      "\n",
      "analyzing Candy_Project_2359-2415_csv.csv:\n",
      "  columns: ['filename', 'file_size', 'file_attributes', 'region_count', 'region_id', 'region_shape_attributes', 'region_attributes']\n",
      "  rows: 200\n",
      "  sample region_attributes:\n",
      "    1. raw: '100_Grand' -> normalized: '100_Grand'\n",
      "    2. raw: 'Midnight_Milky_Way' -> normalized: 'Midnight_Milky_Way'\n",
      "    3. raw: 'Crunch' -> normalized: 'Crunch'\n",
      "\n",
      "analyzing Candy_Project_1982-2038_csv.csv:\n",
      "  columns: ['filename', 'file_size', 'file_attributes', 'region_count', 'region_id', 'region_shape_attributes', 'region_attributes']\n",
      "  rows: 200\n",
      "  sample region_attributes:\n",
      "    1. raw: '100_Grand' -> normalized: '100_Grand'\n",
      "    2. raw: 'Snickers' -> normalized: 'Snickers'\n",
      "    3. raw: 'Butterfingers' -> normalized: 'Butterfinger'\n",
      "\n",
      "analyzing Candy_Project_2147-2197_csv.csv:\n",
      "  columns: ['filename', 'file_size', 'file_attributes', 'region_count', 'region_id', 'region_shape_attributes', 'region_attributes']\n",
      "  rows: 200\n",
      "  sample region_attributes:\n",
      "    1. raw: '100_Grand' -> normalized: '100_Grand'\n",
      "    2. raw: 'Midnight_Milky_Way' -> normalized: 'Midnight_Milky_Way'\n",
      "    3. raw: '3_Musketeers' -> normalized: '3_Musketeers'\n",
      "\n",
      "analyzing Candy_Project_2468-2496_csv.csv:\n",
      "  columns: ['filename', 'file_size', 'file_attributes', 'region_count', 'region_id', 'region_shape_attributes', 'region_attributes']\n",
      "  rows: 112\n",
      "  sample region_attributes:\n",
      "    1. raw: '100_Grand' -> normalized: '100_Grand'\n",
      "    2. raw: 'Midnight_Milky_Way' -> normalized: 'Midnight_Milky_Way'\n",
      "    3. raw: 'Milky_Way' -> normalized: 'Milky_Way'\n",
      "\n",
      "analyzing Candy_Project_2093-2146_csv.csv:\n",
      "  columns: ['filename', 'file_size', 'file_attributes', 'region_count', 'region_id', 'region_shape_attributes', 'region_attributes']\n",
      "  rows: 200\n",
      "  sample region_attributes:\n",
      "    1. raw: 'Milky_Way' -> normalized: 'Milky_Way'\n",
      "    2. raw: 'Crunch' -> normalized: 'Crunch'\n",
      "    3. raw: 'Twix' -> normalized: 'Twix'\n",
      "\n",
      "analyzing Candy_Project_2304-2358_csv.csv:\n",
      "  columns: ['filename', 'file_size', 'file_attributes', 'region_count', 'region_id', 'region_shape_attributes', 'region_attributes']\n",
      "  rows: 200\n",
      "  sample region_attributes:\n",
      "    1. raw: 'Baby_Ruth' -> normalized: 'Baby_Ruth'\n",
      "    2. raw: '3_Musketeers' -> normalized: '3_Musketeers'\n",
      "    3. raw: 'Twix' -> normalized: 'Twix'\n",
      "\n",
      "analyzing Candy_Project_2253-2303_csv.csv:\n",
      "  columns: ['filename', 'file_size', 'file_attributes', 'region_count', 'region_id', 'region_shape_attributes', 'region_attributes']\n",
      "  rows: 200\n",
      "  sample region_attributes:\n",
      "    1. raw: '3_Musketeers' -> normalized: '3_Musketeers'\n",
      "    2. raw: 'Baby_Ruth' -> normalized: 'Baby_Ruth'\n",
      "    3. raw: 'Midnight_Milky_Way' -> normalized: 'Midnight_Milky_Way'\n",
      "\n",
      "analyzing Candy_Project_2416-2467_csv.csv:\n",
      "  columns: ['filename', 'file_size', 'file_attributes', 'region_count', 'region_id', 'region_shape_attributes', 'region_attributes']\n",
      "  rows: 200\n",
      "  sample region_attributes:\n",
      "    1. raw: 'Milky_Way' -> normalized: 'Milky_Way'\n",
      "    2. raw: 'Snickers' -> normalized: 'Snickers'\n",
      "    3. raw: 'Midnight_Milky_Way' -> normalized: 'Midnight_Milky_Way'\n",
      "\n",
      "analyzing Candy_Project_2198-2252_csv.csv:\n",
      "  columns: ['filename', 'file_size', 'file_attributes', 'region_count', 'region_id', 'region_shape_attributes', 'region_attributes']\n",
      "  rows: 200\n",
      "  sample region_attributes:\n",
      "    1. raw: 'Baby_Ruth' -> normalized: 'Baby_Ruth'\n",
      "    2. raw: 'Crunch' -> normalized: 'Crunch'\n",
      "    3. raw: '100_Grand' -> normalized: '100_Grand'\n",
      "total annotations: 33\n",
      "unique classes found: 9\n",
      "classes: ['100_Grand', '3_Musketeers', 'Baby_Ruth', 'Butterfinger', 'Crunch', 'Midnight_Milky_Way', 'Milky_Way', 'Snickers', 'Twix']\n",
      "\n",
      "class distribution:\n",
      "  100_Grand: 6 (18.2%)\n",
      "  Midnight_Milky_Way: 5 (15.2%)\n",
      "  Crunch: 4 (12.1%)\n",
      "  Baby_Ruth: 4 (12.1%)\n",
      "  3_Musketeers: 4 (12.1%)\n",
      "  Milky_Way: 4 (12.1%)\n",
      "  Butterfinger: 2 (6.1%)\n",
      "  Snickers: 2 (6.1%)\n",
      "  Twix: 2 (6.1%)\n",
      "\n",
      "step 1: organizing dataset files\n",
      "organizing dataset files\n",
      "no archive folder found\n",
      "moved 0 images to /Users/larasabha/Desktop/Candy-object-detection/Images\n",
      "moved 0 CSV files to /Users/larasabha/Desktop/Candy-object-detection/Annotation_CSV_Files\n",
      "final counts: 528 images, 11 CSV files\n",
      "\n",
      "step 2: converting CSV to YOLO format\n",
      "converting CSV annotations to YOLO format\n",
      "found 11 CSV files\n",
      "loaded Candy_Project_1930-1981_csv.csv\n",
      "loaded Candy_Project_2039-2092_csv.csv\n",
      "loaded Candy_Project_2359-2415_csv.csv\n",
      "loaded Candy_Project_1982-2038_csv.csv\n",
      "loaded Candy_Project_2147-2197_csv.csv\n",
      "loaded Candy_Project_2468-2496_csv.csv\n",
      "loaded Candy_Project_2093-2146_csv.csv\n",
      "loaded Candy_Project_2304-2358_csv.csv\n",
      "loaded Candy_Project_2253-2303_csv.csv\n",
      "loaded Candy_Project_2416-2467_csv.csv\n",
      "loaded Candy_Project_2198-2252_csv.csv\n",
      "total annotations: 2113\n",
      "normalized classes found: ['100_Grand', '3_Musketeers', 'Baby_Ruth', 'Butterfinger', 'Crunch', 'Midnight_Milky_Way', 'Milky_Way', 'Snickers', 'Twix']\n",
      "final 10 classes: ['Crunch', 'Baby_Ruth', 'Butterfinger', '3_Musketeers', 'Milky_Way', 'Snickers', 'Twix', '100_Grand', 'Midnight_Milky_Way', 'Unknown']\n",
      "class mapping: {'Crunch': 0, 'Baby_Ruth': 1, 'Butterfinger': 2, '3_Musketeers': 3, 'Milky_Way': 4, 'Snickers': 5, 'Twix': 6, '100_Grand': 7, 'Midnight_Milky_Way': 8, 'Unknown': 9}\n",
      "created classes.txt\n",
      "converted 528 image-label pairs, skipped 0\n",
      "created 0 Unknown class annotations from missing/invalid dimensions\n",
      "class distribution: {'Crunch': 248, 'Butterfinger': 248, '100_Grand': 236, 'Baby_Ruth': 249, 'Snickers': 232, 'Twix': 224, '3_Musketeers': 233, 'Milky_Way': 216, 'Midnight_Milky_Way': 227}\n",
      "\n",
      "step 3: creating train/validation split\n",
      "creating train/validation split with class balancing\n",
      "found 528 images and 528 labels\n",
      "found 528 matching image-label pairs\n",
      "class distribution in files: [(8, 227), (2, 248), (5, 232), (6, 224), (3, 233), (4, 216), (0, 247), (7, 236), (1, 249)]\n",
      "stratified split: 527 training, 310 validation\n",
      "successfully created 527 training and 310 validation pairs\n",
      "\n",
      "step 4: creating data.yaml\n",
      "creating data.yaml\n",
      "created data.yaml with 10 classes\n",
      "classes: ['Crunch', 'Baby_Ruth', 'Butterfinger', '3_Musketeers', 'Milky_Way', 'Snickers', 'Twix', '100_Grand', 'Midnight_Milky_Way', 'Unknown']\n",
      "\n",
      "step 5: validating training data\n",
      "training: 527 images, 527 labels\n",
      "validation: 310 images, 310 labels\n",
      "\n",
      "training class distribution (2109 total annotations):\n",
      "  Crunch: 248 (11.8%)\n",
      "  Baby_Ruth: 249 (11.8%)\n",
      "  Butterfinger: 247 (11.7%)\n",
      "  3_Musketeers: 232 (11.0%)\n",
      "  Milky_Way: 215 (10.2%)\n",
      "  Snickers: 232 (11.0%)\n",
      "  Twix: 224 (10.6%)\n",
      "  100_Grand: 236 (11.2%)\n",
      "  Midnight_Milky_Way: 226 (10.7%)\n",
      "  Unknown: 0 (0.0%)\n",
      "\n",
      "class balance analysis:\n",
      "  max/min ratio: 1.16\n",
      "\n",
      "training section\n",
      "\n",
      "testing section\n",
      "Found model: runs/detect/candy_detection9/weights/best.pt\n",
      "\n",
      "model classes analysis:\n",
      "total classes: 9\n",
      "class mapping:\n",
      "  0: 100_Grand\n",
      "  1: 3_Musketeers\n",
      "  2: Baby_Ruth\n",
      "  3: Butterfingers\n",
      "  4: Crunch\n",
      "  5: Midnight_Milky_Way\n",
      "  6: Milky_Way\n",
      "  7: Snickers\n",
      "  8: Twix\n",
      "\n",
      "testing single image: /Users/larasabha/Desktop/image1.jpg\n",
      "testing detection on: /Users/larasabha/Desktop/image1.jpg\n",
      "model loaded: runs/detect/candy_detection9/weights/best.pt\n",
      "model classes: {0: '100_Grand', 1: '3_Musketeers', 2: 'Baby_Ruth', 3: 'Butterfingers', 4: 'Crunch', 5: 'Midnight_Milky_Way', 6: 'Milky_Way', 7: 'Snickers', 8: 'Twix'}\n",
      "image size: 612x612\n",
      "\n",
      "0: 640x640 2 3_Musketeerss, 4 Milky_Ways, 1 Snickers, 1 Twix, 90.0ms\n",
      "Speed: 2.5ms preprocess, 90.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3_Musketeers, 4 Milky_Ways, 1 Snickers, 64.3ms\n",
      "Speed: 2.3ms preprocess, 64.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 Milky_Ways, 1 Snickers, 66.2ms\n",
      "Speed: 1.9ms preprocess, 66.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "found 6 detections:\n",
      "  Snickers: 1 instances (avg conf: 0.967)\n",
      "  Milky_Way: 3 instances (avg conf: 0.785)\n",
      "  Uncertain_3_Musketeers: 1 instances (avg conf: 0.350)\n",
      "  Uncertain_Milky_Way: 1 instances (avg conf: 0.281)\n",
      "\n",
      "detailed detections:\n",
      "  1. Snickers (0.967)\n",
      "  2. Milky_Way (0.851)\n",
      "  3. Milky_Way (0.790)\n",
      "  4. Milky_Way (0.713)\n",
      "  5. Uncertain_3_Musketeers (0.350) [UNCERTAIN]\n",
      "  6. Uncertain_Milky_Way (0.281) [UNCERTAIN]\n",
      "\n",
      "result saved to: /Users/larasabha/Desktop/Candy-object-detection/test_results/detection_image1.jpg\n",
      "\n",
      "testing multiple images...\n",
      "testing detection on images in: Images\n",
      "model loaded with 9 classes: ['100_Grand', '3_Musketeers', 'Baby_Ruth', 'Butterfingers', 'Crunch', 'Midnight_Milky_Way', 'Milky_Way', 'Snickers', 'Twix']\n",
      "found 528 images\n",
      "\n",
      "0: 480x640 1 Butterfingers, 1 Midnight_Milky_Way, 1 Snickers, 1 Twix, 48.9ms\n",
      "Speed: 3.6ms preprocess, 48.9ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "IMG_2165.JPG: 4 detections - Twix(0.99), Butterfingers(0.99), Snickers(0.98), Midnight_Milky_Way(0.98)\n",
      "\n",
      "0: 480x640 1 3_Musketeers, 1 Butterfingers, 1 Midnight_Milky_Way, 1 Snickers, 56.1ms\n",
      "Speed: 4.2ms preprocess, 56.1ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "IMG_2171.JPG: 4 detections - Butterfingers(0.99), Snickers(0.98), Midnight_Milky_Way(0.97), 3_Musketeers(0.97)\n",
      "\n",
      "0: 480x640 1 Butterfingers, 1 Milky_Way, 1 Snickers, 1 Twix, 53.4ms\n",
      "Speed: 2.5ms preprocess, 53.4ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "IMG_2159.JPG: 4 detections - Twix(0.99), Milky_Way(0.98), Butterfingers(0.98), Snickers(0.97)\n",
      "\n",
      "0: 480x640 1 Crunch, 1 Milky_Way, 1 Snickers, 1 Twix, 49.0ms\n",
      "Speed: 2.2ms preprocess, 49.0ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "IMG_2398.JPG: 4 detections - Crunch(0.98), Twix(0.98), Snickers(0.98), Milky_Way(0.97)\n",
      "\n",
      "0: 480x640 1 Crunch, 1 Midnight_Milky_Way, 1 Snickers, 1 Twix, 49.5ms\n",
      "Speed: 2.0ms preprocess, 49.5ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "IMG_2401.JPG: 4 detections - Crunch(0.99), Snickers(0.99), Twix(0.98), Midnight_Milky_Way(0.93)\n",
      "\n",
      "0: 480x640 1 100_Grand, 1 Crunch, 1 Milky_Way, 1 Twix, 57.9ms\n",
      "Speed: 2.3ms preprocess, 57.9ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "IMG_2367.JPG: 4 detections - Twix(0.99), 100_Grand(0.98), Milky_Way(0.98), Crunch(0.97)\n",
      "\n",
      "0: 480x640 1 100_Grand, 1 Crunch, 1 Midnight_Milky_Way, 1 Twix, 52.2ms\n",
      "Speed: 3.9ms preprocess, 52.2ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "IMG_2373.JPG: 4 detections - Twix(0.99), Crunch(0.99), 100_Grand(0.98), Midnight_Milky_Way(0.98)\n",
      "\n",
      "0: 480x640 1 Crunch, 1 Midnight_Milky_Way, 1 Milky_Way, 1 Snickers, 57.5ms\n",
      "Speed: 3.3ms preprocess, 57.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "IMG_2415.JPG: 4 detections - Milky_Way(0.99), Crunch(0.99), Snickers(0.99), Midnight_Milky_Way(0.96)\n",
      "\n",
      "0: 480x640 1 Crunch, 1 Midnight_Milky_Way, 1 Milky_Way, 1 Twix, 53.7ms\n",
      "Speed: 2.0ms preprocess, 53.7ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "IMG_2429.JPG: 4 detections - Twix(0.99), Milky_Way(0.98), Crunch(0.98), Midnight_Milky_Way(0.97)\n",
      "\n",
      "0: 480x640 1 100_Grand, 1 Baby_Ruth, 1 Crunch, 1 Midnight_Milky_Way, 49.9ms\n",
      "Speed: 2.9ms preprocess, 49.9ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "IMG_2213.JPG: 4 detections - Midnight_Milky_Way(0.99), Baby_Ruth(0.98), Crunch(0.98), 100_Grand(0.98)\n",
      "\n",
      "0: 480x640 1 100_Grand, 1 3_Musketeers, 1 Baby_Ruth, 1 Crunch, 51.2ms\n",
      "Speed: 1.9ms preprocess, 51.2ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "IMG_2207.JPG: 4 detections - 100_Grand(0.99), 3_Musketeers(0.99), Baby_Ruth(0.98), Crunch(0.98)\n",
      "\n",
      "0: 480x640 1 100_Grand, 1 Baby_Ruth, 1 Butterfingers, 1 Midnight_Milky_Way, 49.3ms\n",
      "Speed: 2.3ms preprocess, 49.3ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "IMG_2011.JPG: 4 detections - Butterfingers(0.99), 100_Grand(0.99), Baby_Ruth(0.99), Midnight_Milky_Way(0.93)\n",
      "\n",
      "0: 480x640 1 3_Musketeers, 1 Baby_Ruth, 1 Butterfingers, 1 Milky_Way, 48.1ms\n",
      "Speed: 2.1ms preprocess, 48.1ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "IMG_2039.JPG: 4 detections - Butterfingers(0.99), 3_Musketeers(0.98), Milky_Way(0.97), Baby_Ruth(0.97)\n",
      "\n",
      "0: 480x640 1 3_Musketeers, 1 Baby_Ruth, 1 Butterfingers, 1 Milky_Way, 51.7ms\n",
      "Speed: 2.0ms preprocess, 51.7ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "IMG_2038.JPG: 4 detections - Baby_Ruth(0.99), 3_Musketeers(0.98), Milky_Way(0.98), Butterfingers(0.96)\n",
      "\n",
      "0: 480x640 1 100_Grand, 1 3_Musketeers, 1 Baby_Ruth, 1 Butterfingers, 47.7ms\n",
      "Speed: 1.9ms preprocess, 47.7ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "IMG_2004.JPG: 4 detections - Butterfingers(0.99), 100_Grand(0.99), Baby_Ruth(0.98), 3_Musketeers(0.97)\n",
      "\n",
      "0: 480x640 1 100_Grand, 1 Baby_Ruth, 1 Butterfingers, 1 Midnight_Milky_Way, 47.3ms\n",
      "Speed: 2.6ms preprocess, 47.3ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "IMG_2010.JPG: 4 detections - Butterfingers(0.99), 100_Grand(0.97), Midnight_Milky_Way(0.97), Baby_Ruth(0.97)\n",
      "\n",
      "0: 480x640 1 100_Grand, 1 3_Musketeers, 1 Baby_Ruth, 1 Crunch, 47.7ms\n",
      "Speed: 2.4ms preprocess, 47.7ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "IMG_2206.JPG: 4 detections - Baby_Ruth(0.99), 100_Grand(0.97), Crunch(0.96), 3_Musketeers(0.95)\n",
      "\n",
      "0: 480x640 1 100_Grand, 1 Baby_Ruth, 1 Crunch, 1 Midnight_Milky_Way, 45.5ms\n",
      "Speed: 1.9ms preprocess, 45.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "IMG_2212.JPG: 4 detections - Crunch(1.00), 100_Grand(0.99), Baby_Ruth(0.98), Midnight_Milky_Way(0.97)\n",
      "\n",
      "0: 480x640 1 Crunch, 1 Midnight_Milky_Way, 1 Milky_Way, 1 Twix, 46.7ms\n",
      "Speed: 2.0ms preprocess, 46.7ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "IMG_2428.JPG: 4 detections - Twix(0.99), Midnight_Milky_Way(0.99), Milky_Way(0.99), Crunch(0.98)\n",
      "\n",
      "0: 480x640 1 Crunch, 1 Midnight_Milky_Way, 1 Milky_Way, 1 Snickers, 43.9ms\n",
      "Speed: 1.9ms preprocess, 43.9ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "IMG_2414.JPG: 4 detections - Crunch(0.99), Midnight_Milky_Way(0.98), Milky_Way(0.98), Snickers(0.96)\n",
      "\n",
      "0: 480x640 1 Crunch, 1 Milky_Way, 1 Snickers, 1 Twix, 45.5ms\n",
      "Speed: 1.9ms preprocess, 45.5ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "IMG_2400.JPG: 4 detections - Crunch(0.99), Snickers(0.99), Milky_Way(0.98), Twix(0.98)\n",
      "\n",
      "0: 480x640 1 100_Grand, 1 3_Musketeers, 1 Crunch, 1 Twix, 46.2ms\n",
      "Speed: 2.2ms preprocess, 46.2ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "IMG_2366.JPG: 4 detections - Crunch(0.99), 100_Grand(0.99), Twix(0.98), 3_Musketeers(0.97)\n",
      "\n",
      "0: 480x640 1 Crunch, 1 Milky_Way, 1 Snickers, 1 Twix, 46.0ms\n",
      "Speed: 2.4ms preprocess, 46.0ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "IMG_2399.JPG: 4 detections - Twix(0.99), Crunch(0.99), Snickers(0.98), Milky_Way(0.96)\n",
      "\n",
      "0: 480x640 1 3_Musketeers, 1 Butterfingers, 1 Snickers, 1 Twix, 49.3ms\n",
      "Speed: 3.0ms preprocess, 49.3ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "IMG_2158.JPG: 4 detections - Twix(0.99), Butterfingers(0.99), Snickers(0.99), 3_Musketeers(0.99)\n",
      "\n",
      "0: 480x640 1 3_Musketeers, 1 Butterfingers, 1 Milky_Way, 1 Snickers, 57.4ms\n",
      "Speed: 2.2ms preprocess, 57.4ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "IMG_2170.JPG: 4 detections - Milky_Way(0.98), Snickers(0.98), Butterfingers(0.98), 3_Musketeers(0.97)\n",
      "\n",
      "0: 480x640 1 Butterfingers, 1 Midnight_Milky_Way, 1 Snickers, 1 Twix, 74.3ms\n",
      "Speed: 3.6ms preprocess, 74.3ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "IMG_2164.JPG: 4 detections - Butterfingers(0.99), Twix(0.99), Snickers(0.97), Midnight_Milky_Way(0.95)\n",
      "\n",
      "0: 480x640 1 100_Grand, 1 Baby_Ruth, 1 Crunch, 1 Snickers, 67.2ms\n",
      "Speed: 2.7ms preprocess, 67.2ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "IMG_2199.JPG: 4 detections - Snickers(0.99), 100_Grand(0.99), Crunch(0.99), Baby_Ruth(0.98)\n",
      "\n",
      "0: 480x640 1 3_Musketeers, 1 Butterfingers, 1 Midnight_Milky_Way, 1 Snickers, 54.9ms\n",
      "Speed: 2.0ms preprocess, 54.9ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "IMG_2172.JPG: 4 detections - Butterfingers(0.99), Midnight_Milky_Way(0.99), 3_Musketeers(0.97), Snickers(0.96)\n",
      "\n",
      "0: 480x640 1 Butterfingers, 1 Midnight_Milky_Way, 1 Snickers, 1 Twix, 50.0ms\n",
      "Speed: 2.5ms preprocess, 50.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "IMG_2166.JPG: 4 detections - Twix(0.99), Snickers(0.99), Butterfingers(0.99), Midnight_Milky_Way(0.96)\n",
      "\n",
      "0: 480x640 1 Crunch, 1 Midnight_Milky_Way, 1 Milky_Way, 1 Snickers, 52.4ms\n",
      "Speed: 2.4ms preprocess, 52.4ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "IMG_2416.JPG: 4 detections - Snickers(0.99), Milky_Way(0.99), Crunch(0.97), Midnight_Milky_Way(0.96)\n",
      "\n",
      "0: 480x640 1 100_Grand, 1 Crunch, 1 Milky_Way, 1 Twix, 52.1ms\n",
      "Speed: 2.2ms preprocess, 52.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "IMG_2370.JPG: 4 detections - Crunch(0.99), 100_Grand(0.99), Milky_Way(0.98), Twix(0.97)\n",
      "\n",
      "0: 480x640 1 100_Grand, 1 3_Musketeers, 1 Crunch, 1 Twix, 59.8ms\n",
      "Speed: 3.0ms preprocess, 59.8ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "IMG_2364.JPG: 4 detections - Twix(0.99), Crunch(0.99), 100_Grand(0.98), 3_Musketeers(0.96)\n",
      "\n",
      "0: 480x640 1 Crunch, 1 Midnight_Milky_Way, 1 Snickers, 1 Twix, 49.8ms\n",
      "Speed: 2.1ms preprocess, 49.8ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "IMG_2402.JPG: 4 detections - Twix(0.99), Crunch(0.99), Snickers(0.99), Midnight_Milky_Way(0.95)\n",
      "\n",
      "0: 480x640 1 100_Grand, 1 Crunch, 1 Milky_Way, 1 Snickers, 48.0ms\n",
      "Speed: 2.2ms preprocess, 48.0ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "IMG_2358.JPG: 4 detections - Crunch(0.99), Milky_Way(0.98), 100_Grand(0.98), Snickers(0.98)\n",
      "\n",
      "0: 480x640 1 100_Grand, 1 3_Musketeers, 1 Baby_Ruth, 1 Crunch, 51.6ms\n",
      "Speed: 2.7ms preprocess, 51.6ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "IMG_2204.JPG: 4 detections - Baby_Ruth(0.98), 100_Grand(0.98), Crunch(0.98), 3_Musketeers(0.95)\n",
      "\n",
      "0: 480x640 1 100_Grand, 1 Baby_Ruth, 1 Crunch, 1 Milky_Way, 49.2ms\n",
      "Speed: 2.6ms preprocess, 49.2ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "IMG_2210.JPG: 4 detections - Milky_Way(0.99), 100_Grand(0.98), Baby_Ruth(0.98), Crunch(0.98)\n",
      "\n",
      "0: 480x640 1 Baby_Ruth, 1 Butterfingers, 1 Snickers, 1 Twix, 49.3ms\n",
      "Speed: 2.1ms preprocess, 49.3ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "IMG_2012.JPG: 4 detections - Snickers(0.99), Butterfingers(0.99), Baby_Ruth(0.99), Twix(0.96)\n",
      "\n",
      "0: 480x640 1 Baby_Ruth, 1 Butterfingers, 1 Snickers, 1 Twix, 48.3ms\n",
      "Speed: 2.0ms preprocess, 48.3ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "IMG_2013.JPG: 4 detections - Twix(0.99), Butterfingers(0.99), Baby_Ruth(0.99), Snickers(0.98)\n",
      "\n",
      "0: 480x640 1 100_Grand, 1 Baby_Ruth, 1 Butterfingers, 1 Midnight_Milky_Way, 50.1ms\n",
      "Speed: 2.2ms preprocess, 50.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "IMG_2007.JPG: 4 detections - 100_Grand(0.99), Butterfingers(0.99), Midnight_Milky_Way(0.99), Baby_Ruth(0.98)\n",
      "\n",
      "0: 480x640 1 100_Grand, 1 Baby_Ruth, 1 Crunch, 1 Milky_Way, 51.1ms\n",
      "Speed: 2.2ms preprocess, 51.1ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "IMG_2211.JPG: 4 detections - Baby_Ruth(0.99), Milky_Way(0.98), Crunch(0.98), 100_Grand(0.98)\n",
      "\n",
      "0: 480x640 1 100_Grand, 1 3_Musketeers, 1 Baby_Ruth, 1 Crunch, 46.7ms\n",
      "Speed: 2.3ms preprocess, 46.7ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "IMG_2205.JPG: 4 detections - Baby_Ruth(0.98), Crunch(0.98), 3_Musketeers(0.96), 100_Grand(0.96)\n",
      "\n",
      "0: 480x640 1 100_Grand, 1 Crunch, 1 Midnight_Milky_Way, 1 Snickers, 48.9ms\n",
      "Speed: 2.6ms preprocess, 48.9ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "IMG_2359.JPG: 4 detections - Crunch(0.99), 100_Grand(0.97), Midnight_Milky_Way(0.97), Snickers(0.97)\n",
      "\n",
      "0: 480x640 1 100_Grand, 1 3_Musketeers, 1 Crunch, 1 Twix, 51.1ms\n",
      "Speed: 2.1ms preprocess, 51.1ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "IMG_2365.JPG: 4 detections - 100_Grand(0.99), Crunch(0.99), Twix(0.98), 3_Musketeers(0.96)\n",
      "\n",
      "0: 480x640 1 Crunch, 1 Midnight_Milky_Way, 1 Snickers, 1 Twix, 55.5ms\n",
      "Speed: 2.2ms preprocess, 55.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "IMG_2403.JPG: 4 detections - Twix(0.99), Crunch(0.99), Snickers(0.98), Midnight_Milky_Way(0.98)\n",
      "\n",
      "0: 480x640 1 Crunch, 1 Midnight_Milky_Way, 1 Milky_Way, 1 Snickers, 48.5ms\n",
      "Speed: 1.9ms preprocess, 48.5ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "IMG_2417.JPG: 4 detections - Crunch(0.99), Milky_Way(0.98), Midnight_Milky_Way(0.96), Snickers(0.95)\n",
      "\n",
      "0: 480x640 1 100_Grand, 1 Crunch, 1 Midnight_Milky_Way, 1 Twix, 50.3ms\n",
      "Speed: 2.0ms preprocess, 50.3ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "IMG_2371.JPG: 4 detections - Crunch(0.99), Twix(0.98), Midnight_Milky_Way(0.98), 100_Grand(0.98)\n",
      "\n",
      "0: 480x640 1 3_Musketeers, 1 Butterfingers, 1 Milky_Way, 1 Snickers, 47.9ms\n",
      "Speed: 2.1ms preprocess, 47.9ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "IMG_2167.JPG: 4 detections - Butterfingers(0.99), Milky_Way(0.98), Snickers(0.98), 3_Musketeers(0.97)\n",
      "\n",
      "0: 480x640 1 3_Musketeers, 1 Butterfingers, 1 Midnight_Milky_Way, 1 Snickers, 50.5ms\n",
      "Speed: 2.7ms preprocess, 50.5ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "IMG_2173.JPG: 4 detections - Snickers(0.99), 3_Musketeers(0.99), Butterfingers(0.99), Midnight_Milky_Way(0.98)\n",
      "\n",
      "0: 480x640 1 100_Grand, 1 Baby_Ruth, 1 Crunch, 1 Snickers, 49.2ms\n",
      "Speed: 2.0ms preprocess, 49.2ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "IMG_2198.JPG: 4 detections - Crunch(0.99), Baby_Ruth(0.98), Snickers(0.97), 100_Grand(0.97)\n",
      "\n",
      "0: 480x640 1 Butterfingers, 1 Midnight_Milky_Way, 1 Milky_Way, 1 Twix, 50.8ms\n",
      "Speed: 2.7ms preprocess, 50.8ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "IMG_2188.JPG: 4 detections - Butterfingers(1.00), Twix(0.99), Milky_Way(0.99), Midnight_Milky_Way(0.99)\n",
      "images processed: 50\n",
      "images with detections: 50\n",
      "total detections: 200\n",
      "average detections per image: 4.00\n",
      "detection rate: 100.0%\n",
      "average confidence: 0.980\n",
      "confidence range: 0.930 - 0.995\n",
      "\n",
      "class distribution:\n",
      "  Crunch: 31 (15.5%)\n",
      "  Snickers: 26 (13.0%)\n",
      "  Midnight_Milky_Way: 24 (12.0%)\n",
      "  Twix: 23 (11.5%)\n",
      "  100_Grand: 23 (11.5%)\n",
      "  Milky_Way: 20 (10.0%)\n",
      "  Butterfingers: 19 (9.5%)\n",
      "  Baby_Ruth: 18 (9.0%)\n",
      "  3_Musketeers: 16 (8.0%)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    print(\"step 0: analyzing CSV data\")\n",
    "    analyze_csv_data()\n",
    "    \n",
    "    print(\"\\nstep 1: organizing dataset files\")\n",
    "    if not organize_dataset_files(project_root):\n",
    "        print(\"failed to organize dataset files\")\n",
    "        exit(1)\n",
    "    \n",
    "    print(\"\\nstep 2: converting CSV to YOLO format\")\n",
    "    if not convert_csv_to_yolo():\n",
    "        print(\"failed to convert CSV to YOLO format\")\n",
    "        exit(1)\n",
    "    \n",
    "    print(\"\\nstep 3: creating train/validation split\")\n",
    "    if not create_train_val_split():\n",
    "        print(\"failed to create train/val split\")\n",
    "        exit(1)\n",
    "    \n",
    "    print(\"\\nstep 4: creating data.yaml\")\n",
    "    if not create_data_yaml(project_root):\n",
    "        print(\"failed to create data.yaml\")\n",
    "        exit(1)\n",
    "    \n",
    "    print(\"\\nstep 5: validating training data\")\n",
    "    validate_training_data(project_root)\n",
    "    \n",
    "    print(\"\\ntraining section\")\n",
    "    # print(\"to train the model, uncomment:\")\n",
    "    # print(\"# train_model(epochs=100)\")\n",
    "    # train_model(epochs=100)\n",
    "    \n",
    "    print(\"\\ntesting section\")\n",
    "    model_path = find_best_model()\n",
    "    if model_path:\n",
    "        # analyze model classes\n",
    "        analyze_model_classes(model_path)\n",
    "        \n",
    "        # test single image with detection\n",
    "        desktop_image = str(Path.home() / \"Desktop\" / \"image1.jpg\")\n",
    "        if os.path.exists(desktop_image):\n",
    "            print(f\"\\ntesting single image: {desktop_image}\")\n",
    "            test_single_image(desktop_image, model_path)\n",
    "        \n",
    "        # test multiple images with analysis\n",
    "        if Path(\"Images\").exists():\n",
    "            print(f\"\\ntesting multiple images...\")\n",
    "            test_multiple_images(\"Images\", model_path)\n",
    "    else:\n",
    "        print(\"no trained model found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b143775-64b9-4b4f-b576-3143cd371e82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Candy Detector Env",
   "language": "python",
   "name": "my_candy_detector"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
